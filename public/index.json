[
{
	"uri": "https://banh251o.github.io/EMR-Cost-Optimization-Workshop/",
	"title": "EMR Cost Optimization Workshop",
	"tags": [],
	"description": "",
	"content": "EMR Cost Optimization Workshop Save up to 70% on Amazon EMR Costs Welcome to the comprehensive Amazon EMR Cost Optimization Workshop! Learn proven strategies to dramatically reduce your EMR costs while maintaining performance and reliability.\nüéØ Workshop Objectives By the end of this workshop, you will:\nReduce EMR costs by 60-70% using spot instances and auto scaling Implement proactive monitoring with automated alerts and remediation Master production-ready cost optimization techniques Deploy enterprise-grade monitoring and governance üí∞ Expected Cost Savings Company Size Before After Monthly Savings Small $2,000 $600 $1,400 Medium $10,000 $3,000 $7,000 Large $40,000 $12,000 $28,000 üìö Workshop Structure Part 1: Spot Instances (39% Savings) Mixed instance groups Interruption handling Best practices Part 2: Auto Scaling (40% Additional Savings) Managed scaling policies Custom metrics Performance optimization Part 3: Monitoring \u0026amp; Alerting (15% Additional Savings) Real-time cost tracking Automated remediation Production dashboards Part 4: Resource Cleanup Complete cleanup procedures Cost verification Best practices üéì Target Audience Primary:\nData Engineers (2+ years experience) DevOps Engineers (AWS knowledge) Solutions Architects (cost optimization focus) Secondary:\nSenior Developers (big data experience) Cloud Engineers (EMR experience) Technical Leads (cost management) ‚è±Ô∏è Duration Total Time: 4-6 hours\nPart 1: 1.5 hours Part 2: 2 hours Part 3: 2.5 hours Part 4: 30 minutes üìã Prerequisites Required Knowledge ‚úÖ AWS basics (EC2, S3, IAM) ‚úÖ EMR/Spark fundamentals ‚úÖ Command line experience ‚úÖ Basic Python knowledge Required Access ‚úÖ AWS account with EMR permissions ‚úÖ AWS CLI configured ‚úÖ $50-100 budget for hands-on labs Recommended Tools ‚úÖ AWS CLI v2 ‚úÖ Python 3.7+ ‚úÖ Text editor/IDE ‚úÖ Web browser üöÄ Getting Started Setup Prerequisites - Configure your environment Part 1: Spot Instances - Implement 39% cost savings Part 2: Auto Scaling - Add 40% more savings Part 3: Monitoring - Complete observability Part 4: Cleanup - Clean up resources üèÜ Success Metrics After completing this workshop:\n70% cost reduction achieved 99.9% uptime maintained 80% less manual intervention required Production-ready monitoring deployed üí° Key Technologies Amazon EMR - Managed Hadoop/Spark EC2 Spot Instances - Up to 90% savings Auto Scaling - Dynamic capacity management CloudWatch - Monitoring and alerting Lambda - Automated remediation SNS - Alert notifications üéâ What You\u0026rsquo;ll Build A complete, production-ready EMR cost optimization system featuring:\nIntelligent spot instance management Dynamic auto scaling policies Real-time cost monitoring Automated remediation Executive dashboards Pro Tip: This workshop pays for itself by preventing just one cost overrun incident!\nReady to save thousands on your EMR costs? Let\u0026rsquo;s get started!\n"
},
{
	"uri": "https://banh251o.github.io/EMR-Cost-Optimization-Workshop/1-spot-instances/",
	"title": "Part 1: Spot Instances",
	"tags": [],
	"description": "",
	"content": "Part 1: Using Spot Instances for Cost Reduction In this section, you\u0026rsquo;ll learn how to create EMR clusters using Spot Instances to reduce costs by 60-70% compared to On-Demand instances.\nWhat are Spot Instances? Spot Instances are unused EC2 instances from AWS, sold at much lower prices than On-Demand. However, AWS can reclaim them anytime when there\u0026rsquo;s demand.\nAdvantages:\n50-90% cheaper than On-Demand Suitable for workloads that can handle interruption Well integrated with EMR Disadvantages:\nCan be terminated anytime Not suitable for critical workloads Need to design applications to handle interruption Strategy for Using Spot with EMR 1. Mixed Instance Types Use multiple instance types to increase availability:\nm5.large, m4.large, c5.large If one type gets terminated, others continue running 2. Role Distribution Master node: Always use On-Demand (most critical) Core nodes: Part On-Demand, part Spot Task nodes: 100% Spot (can terminate without data loss) 3. Bidding Strategy Set bid price 10-20% higher than current spot price Monitor spot price history to set reasonable prices Hands-on: Create EMR Cluster with Spot Step 1: Preparation Before creating cluster, you need:\nLogin to AWS Console Select region (recommended: us-east-1) Create EC2 Key Pair if not exists Check IAM roles: EMR_DefaultRole and EMR_EC2_DefaultRole Step 2: Create Cluster via Console Open AWS Console ‚Üí EMR Click \u0026ldquo;Create cluster\u0026rdquo; Select \u0026ldquo;Go to advanced options\u0026rdquo; Software Configuration:\nRelease: emr-6.15.0 Applications: Spark, Hadoop Hardware Configuration:\nMaster: 1 x m5.xlarge (On-Demand) Core: 1 x m5.large (On-Demand) + 2 x m5.large (Spot, bid $0.05) Task: 4 x m5.large (Spot, bid $0.05) General Configuration:\nCluster name: \u0026ldquo;Workshop-Spot-Cluster\u0026rdquo; Logging: Enable (select S3 bucket) Termination protection: Disable Step 3: Monitor Cluster After creating cluster:\nMonitor status in EMR Console Check Hardware tab to view instances View Spot price history in EC2 Console Step 4: Cost Comparison On-Demand Configuration:\nMaster: 1 x m5.xlarge = $0.192/hour Workers: 6 x m5.large = $0.576/hour Total: $0.768/hour Spot Configuration:\nMaster: 1 x m5.xlarge = $0.192/hour Core On-Demand: 1 x m5.large = $0.096/hour Spot instances: 6 x m5.large = $0.180/hour (assuming spot price $0.03) Total: $0.468/hour Savings: 39% ($0.30/hour)\nHandling Spot Interruption Monitoring Interruptions EMR automatically handles spot interruptions:\nTask nodes terminated: Jobs are redistributed Core nodes terminated: Data is replicated Cluster continues running with remaining instances Best Practices Frequent checkpointing: Save intermediate results Use S3: Store data outside cluster Mixed instance types: Reduce risk of all being terminated together Monitor spot prices: Adjust bid prices when needed Lab Exercise: Test Spot Interruption Create Test Job SSH to master node Create test job file: # simple-job.py from pyspark.sql import SparkSession import time spark = SparkSession.builder.appName(\u0026#34;SpotTest\u0026#34;).getOrCreate() # Create large dataset df = spark.range(0, 10000000).toDF(\u0026#34;id\u0026#34;) df = df.repartition(100) # Run long job to test interruption for i in range(10): result = df.count() print(f\u0026#34;Iteration {i}: Count = {result}\u0026#34;) time.sleep(60) # Wait 1 minute spark.stop() Submit job: spark-submit simple-job.py Simulate Interruption In EC2 Console, terminate a spot instance Observe job continues running Check EMR Console for cluster status Part 1 Results After completing this section, you have: ‚úÖ Understood how Spot Instances work with EMR ‚úÖ Created cluster with mixed instance types ‚úÖ Saved 39% cost compared to On-Demand ‚úÖ Tested spot interruption handling Actual cost: Cluster running 1 hour = ~$0.47 (instead of $0.77) Congratulations! You\u0026rsquo;ve successfully created an EMR cluster with Spot Instances and achieved significant cost savings. Next, we\u0026rsquo;ll learn Auto Scaling for further optimization.\rNote: Don\u0026rsquo;t terminate the cluster yet! We\u0026rsquo;ll use this cluster for Part 2: Auto Scaling.\rFrequently Asked Questions Q: Are spot instances reliable? A: With EMR, spot instances are very reliable because EMR automatically handles interruptions. Just need to design jobs properly. Q: When should I use Spot instances? A: Spot instances are suitable for batch processing, data analysis, machine learning training - workloads that can be restarted. Q: How do I know the right bid price? A: Check Spot Price History in EC2 Console, set bid 10-20% higher than average price. Q: What if all spot instances get terminated? A: EMR will automatically launch new instances. Jobs can restart from the nearest checkpoint. Next: Part 2: Auto Scaling to learn how to automatically adjust cluster size based on workload. "
},
{
	"uri": "https://banh251o.github.io/EMR-Cost-Optimization-Workshop/2-auto-scaling/",
	"title": "Part 2: Auto Scaling",
	"tags": [],
	"description": "",
	"content": "Part 2: EMR Auto Scaling - Dynamic Workload Adjustment In this section, you\u0026rsquo;ll learn how to set up EMR Auto Scaling to automatically adjust the number of instances in your cluster based on workload, optimizing both cost and performance.\nWhat is EMR Auto Scaling? EMR Auto Scaling automatically adjusts the number of instances in your cluster based on:\nYARN metrics: Memory and CPU utilization Custom metrics: Custom CloudWatch metrics Time-based scaling: Scheduled scaling patterns Benefits:\nCost savings during low workload periods Improved performance during high workload periods No manual intervention required Great integration with Spot Instances Types of Auto Scaling 1. EMR Managed Scaling (Recommended) Fully managed by AWS Based on YARN container pending metrics Simple and effective Supports both On-Demand and Spot instances 2. Custom Auto Scaling Define your own scaling policies Based on CloudWatch metrics More flexible but complex Suitable for special use cases Hands-on: Setting up Managed Scaling Step 1: Enable Managed Scaling Using the cluster from Part 1, we\u0026rsquo;ll enable auto scaling:\nOpen EMR Console Select cluster \u0026ldquo;Workshop-Spot-Cluster\u0026rdquo; Go to \u0026ldquo;Configuration\u0026rdquo; tab Click \u0026ldquo;Edit\u0026rdquo; in the \u0026ldquo;Scaling\u0026rdquo; section Managed Scaling Configuration:\nMinimum capacity: 2 instances Maximum capacity: 10 instances Maximum On-Demand capacity: 4 instances Step 2: Configure Advanced Settings Scale-out settings:\nScale out cooldown: 300 seconds Maximum scale-out increment: 100% Scale-in settings:\nScale in cooldown: 300 seconds Maximum scale-in increment: 50% Step 3: Verify Configuration After enabling, check:\nScaling status: \u0026ldquo;Enabled\u0026rdquo; Current capacity: 7 instances (from Part 1) Target capacity: Will change based on workload Testing Auto Scaling Create Workload to Test Scaling SSH to Master Node: ssh -i your-key.pem hadoop@master-public-ip\nCreate Test Script: ``python\nscaling-test.py from pyspark.sql import SparkSession import time\nspark = SparkSession.builder .appName(\u0026ldquo;AutoScalingTest\u0026rdquo;) .config(\u0026ldquo;spark.sql.adaptive.enabled\u0026rdquo;, \u0026ldquo;false\u0026rdquo;) .config(\u0026ldquo;spark.sql.adaptive.coalescePartitions.enabled\u0026rdquo;, \u0026ldquo;false\u0026rdquo;) .getOrCreate()\nprint(\u0026quot;=== Starting Auto Scaling Test ===\u0026quot;)\nCreate large dataset to trigger scaling print(\u0026ldquo;Creating large dataset\u0026hellip;\u0026rdquo;) df = spark.range(0, 100000000).toDF(\u0026ldquo;id\u0026rdquo;) df = df.repartition(200) # Many partitions to require more resources\nCache to consume memory df.cache()\nRun multiple operations to maintain load for i in range(5): print(f\u0026quot;Running operation {i+1}/5\u0026hellip;\u0026quot;)\n# Heavy computation\rresult = df.filter(df.id % 2 == 0).count()\rprint(f\u0026quot;Even numbers count: {result}\u0026quot;)\r# Keep load for 5 minutes to observe scaling\rtime.sleep(300)\rprint(\u0026quot;=== Test completed ===\u0026quot;) spark.stop() ``\nSubmit Job: spark-submit \\\r--executor-memory 2g \\\r--num-executors 15 \\\r--executor-cores 2 \\\rscaling-test.py Monitor Scaling Process In EMR Console:\nGo to \u0026ldquo;Hardware\u0026rdquo; tab to view instances Refresh every 2-3 minutes Observe instance count increasing In CloudWatch:\nOpen CloudWatch Console Go to \u0026ldquo;Metrics\u0026rdquo; ‚Üí \u0026ldquo;AWS/ElasticMapReduce\u0026rdquo; Select metrics: YARNMemoryAvailablePercentage ContainerPending AppsRunning Expected Behavior:\nMinutes 0-2: Job starts, YARN memory decreases Minutes 2-5: ContainerPending increases, scaling triggered Minutes 5-8: New instances added (2-3 instances) Minutes 8-25: Job runs with new capacity Minutes 25-30: Job completes, scaling down begins Monitoring and Troubleshooting Key Metrics to Monitor YARN Metrics:\nYARNMemoryAvailablePercentage: \u0026lt; 15% triggers scale out ContainerPending: \u0026gt; 0 for 5 minutes triggers scale out AppsRunning: Number of running applications EMR Metrics:\nRunningMapTasks: Running map tasks RunningReduceTasks: Running reduce tasks TotalLoad: Total cluster load Common Issues and Solutions Issue 1: Scaling not working\nCheck IAM permissions Verify scaling limits (min/max capacity) Check cooldown periods Issue 2: Scale out too slow\nReduce scale-out cooldown Increase maximum scale-out increment Use multiple instance types Issue 3: Scale in too aggressive\nIncrease scale-in cooldown Reduce maximum scale-in increment Adjust YARN memory thresholds Advanced Scaling Strategies 1. Mixed Instance Types for Scaling Configure multiple instance types to increase availability:\nInstance Fleet Configuration:\nPrimary: m5.large (Spot) Secondary: m4.large (Spot) Fallback: c5.large (Spot) Emergency: m5.large (On-Demand) 2. Time-based Scaling For workloads with fixed patterns:\nScale out before peak hours Scale in after off-peak hours Use CloudWatch Events + Lambda 3. Predictive Scaling Based on historical data:\nAnalyze past workload patterns Pre-scale for expected load Combine with reactive scaling Cost Optimization with Auto Scaling Before Auto Scaling (Static Cluster) Peak capacity: 10 instances √ó 8 hours = 80 instance-hours Cost: 80 √ó $0.096 = $7.68/day After Auto Scaling (Dynamic Cluster) Average capacity: 4 instances √ó 8 hours = 32 instance-hours Peak capacity: 8 instances √ó 2 hours = 16 instance-hours Total: 32 + 16 = 48 instance-hours Cost: 48 √ó $0.096 = $4.61/day Savings: $3.07/day (40% cost reduction)\nLab Exercise: Custom Scaling Policy Create Custom CloudWatch Alarm Create Scale-Out Alarm: aws cloudwatch put-metric-alarm \\\r--alarm-name \u0026quot;EMR-ScaleOut-HighMemory\u0026quot; \\\r--alarm-description \u0026quot;Scale out when memory usage \u0026gt; 80%\u0026quot; \\\r--metric-name YARNMemoryAvailablePercentage \\\r--namespace AWS/ElasticMapReduce \\\r--statistic Average \\\r--period 300 \\\r--threshold 20 \\\r--comparison-operator LessThanThreshold \\\r--evaluation-periods 2 \\\r--dimensions Name=JobFlowId,Value=j-xxxxx\nCreate Scale-In Alarm: aws cloudwatch put-metric-alarm \\\r--alarm-name \u0026quot;EMR-ScaleIn-LowMemory\u0026quot; \\\r--alarm-description \u0026quot;Scale in when memory usage \u0026lt; 30%\u0026quot; \\\r--metric-name YARNMemoryAvailablePercentage \\\r--namespace AWS/ElasticMapReduce \\\r--statistic Average \\\r--period 600 \\\r--threshold 70 \\\r--comparison-operator GreaterThanThreshold \\\r--evaluation-periods 3 \\\r--dimensions Name=JobFlowId,Value=j-xxxxx\nTest Custom Scaling Create Light Workload: ``python light-workload.py from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\u0026ldquo;LightWorkload\u0026rdquo;).getOrCreate()\nSmall dataset df = spark.range(0, 1000000).toDF(\u0026ldquo;id\u0026rdquo;) result = df.count() print(f\u0026quot;Light workload result: {result}\u0026quot;)\nspark.stop() ``\nSubmit and Monitor: spark-submit light-workload.py\nObserve Scale-In:\nMemory usage drops below 30% After 10 minutes, cluster scales in Instances reduce from 8 to 4 Production Best Practices 1. Scaling Configuration Recommended Settings:\nMin capacity: 20% of peak capacity Max capacity: 150% of expected peak Scale-out cooldown: 300 seconds Scale-in cooldown: 600 seconds 2. Instance Mix Strategy Optimal Mix:\n30% On-Demand (stability) 70% Spot (cost savings) Multiple instance families Diversified AZs 3. Application Design Scaling-Friendly Applications:\nStateless processing Checkpointing enabled Graceful handling of node loss Appropriate data partitioning 4. Monitoring Setup Essential Metrics:\nCluster utilization Scaling events Job completion times Cost per job Part 2 Results After completing this section, you have:\n‚úÖ Successfully set up EMR Managed Scaling ‚úÖ Tested scaling with real workload ‚úÖ Understood how to monitor scaling metrics ‚úÖ Optimized an additional 40% cost with dynamic scaling Total savings so far:\nSpot Instances: 39% (from Part 1) Auto Scaling: 40% (from Part 2) Combined savings: ~65% compared to static On-Demand cluster Excellent! Your cluster now automatically scales based on workload and maximizes cost savings. Next, we\u0026rsquo;ll set up monitoring to track everything.\nTroubleshooting Common Issues Issue: Scaling Events Not Appearing Possible Causes:\nIAM role missing permissions Cooldown period not expired Metrics not reaching threshold Solutions:\nCheck CloudTrail logs Verify EMR service role permissions Adjust threshold values Issue: Scale-in Too Aggressive Symptoms:\nInstances terminated while jobs running Performance degradation Solutions:\nIncrease scale-in cooldown to 900s Reduce maximum scale-in increment to 25% Set higher memory threshold (80% instead of 70%) Issue: Spot Instances Not Added During Scaling Causes:\nSpot capacity not available Bid price too low Instance type constraints Solutions:\nAdd multiple instance types Increase bid price Enable multiple AZs Performance Tuning Tips 1. Optimize Spark Configuration # Spark configs for auto-scaling environment\rspark.dynamicAllocation.enabled=true\rspark.dynamicAllocation.minExecutors=2\rspark.dynamicAllocation.maxExecutors=50\rspark.dynamicAllocation.initialExecutors=5\n2. YARN Configuration ``xml\n3. EMR Steps Optimization Use cluster mode instead of client mode Enable speculation for fault tolerance Configure appropriate parallelism Real-world Example: E-commerce Analytics Scenario E-commerce company needs to process daily log data:\nMorning (6-10 AM): Light processing (2-3 instances) Afternoon (2-6 PM): Heavy analytics (8-12 instances) Night (10 PM-2 AM): Batch reports (4-6 instances) Auto Scaling Configuration # Managed scaling policy\r{\r\u0026quot;ComputeLimits\u0026quot;: {\r\u0026quot;UnitType\u0026quot;: \u0026quot;Instances\u0026quot;,\r\u0026quot;MinimumCapacityUnits\u0026quot;: 2,\r\u0026quot;MaximumCapacityUnits\u0026quot;: 15,\r\u0026quot;MaximumOnDemandCapacityUnits\u0026quot;: 5,\r\u0026quot;MaximumCoreCapacityUnits\u0026quot;: 8\r}\r}\nCost Comparison Before Auto Scaling:\nStatic 12 instances √ó 24 hours = 288 instance-hours Cost: 288 √ó $0.096 = $27.65/day After Auto Scaling:\nAverage 5 instances √ó 24 hours = 120 instance-hours Cost: 120 √ó $0.096 = $11.52/day Savings: $16.13/day (58%) Advanced Monitoring Setup Custom Metrics Dashboard Create CloudWatch dashboard with:\nCluster capacity over time Cost per hour tracking Job completion rates Scaling events timeline Automated Alerts Setup alerts for:\nScaling failures High cost thresholds Performance degradation Spot interruption rates Cost Tracking Script ``python\ncost-tracker.py import boto3 from datetime import datetime, timedelta\ndef track_emr_costs(cluster_id): emr = boto3.client(\u0026rsquo;emr\u0026rsquo;) ce = boto3.client(\u0026lsquo;ce\u0026rsquo;)\n# Get cluster info\rcluster = emr.describe_cluster(ClusterId=cluster_id)\rstart_time = cluster['Cluster']['Status']['Timeline']['CreationDateTime']\r# Calculate cost\rend_time = datetime.now()\rresponse = ce.get_cost_and_usage(\rTimePeriod={\r'Start': start_time.strftime('%Y-%m-%d'),\r'End': end_time.strftime('%Y-%m-%d')\r},\rGranularity='DAILY',\rMetrics=['BlendedCost'],\rGroupBy=[\r{'Type': 'DIMENSION', 'Key': 'SERVICE'}\r]\r)\rprint(f\u0026quot;Cluster {cluster_id} cost tracking:\u0026quot;)\rfor result in response['ResultsByTime']:\rfor group in result['Groups']:\rif 'ElasticMapReduce' in group['Keys'][0]:\rcost = group['Metrics']['BlendedCost']['Amount']\rprint(f\u0026quot;Date: {result['TimePeriod']['Start']}, Cost: ${cost}\u0026quot;)\rUsage track_emr_costs(\u0026lsquo;j-xxxxx\u0026rsquo;) ``\nScaling Patterns Analysis Pattern 1: Batch Processing Characteristics:\nPredictable workload times High resource usage during processing Idle periods between jobs Optimal Strategy:\nAggressive scale-out (200% increment) Conservative scale-in (25% increment) Longer cooldown periods (600s) Pattern 2: Interactive Analytics Characteristics:\nUnpredictable query patterns Variable resource requirements Need for quick response times Optimal Strategy:\nModerate scale-out (100% increment) Quick scale-in (50% increment) Shorter cooldown periods (300s) Pattern 3: Streaming Workloads Characteristics:\nContinuous data processing Steady resource usage Occasional spikes Optimal Strategy:\nConservative scaling (50% increment) Maintain minimum baseline Focus on stability over cost Integration with Other AWS Services 1. Lambda Triggers Automatically start/stop clusters: ``python\nlambda-emr-scheduler.py import boto3 import json\ndef lambda_handler(event, context): emr = boto3.client(\u0026rsquo;emr\u0026rsquo;)\nif event['action'] == 'start':\r# Start cluster with auto-scaling\rresponse = emr.run_job_flow(\rName='Scheduled-Cluster',\rReleaseLabel='emr-6.15.0',\rInstances={\r'MasterInstanceType': 'm5.xlarge',\r'SlaveInstanceType': 'm5.large',\r'InstanceCount': 3,\r'Ec2KeyName': 'your-key'\r},\rApplications=[{'Name': 'Spark'}],\rServiceRole='EMR_DefaultRole',\rJobFlowRole='EMR_EC2_DefaultRole'\r)\rcluster_id = response['JobFlowId']\r# Enable managed scaling\remr.put_managed_scaling_policy(\rClusterId=cluster_id,\rManagedScalingPolicy={\r'ComputeLimits': {\r'UnitType': 'Instances',\r'MinimumCapacityUnits': 2,\r'MaximumCapacityUnits': 10\r}\r}\r)\rreturn {'statusCode': 200, 'body': f'Started cluster: {cluster_id}'}\relif event['action'] == 'stop':\r# Terminate cluster\remr.terminate_job_flows(JobFlowIds=[event['cluster_id']])\rreturn {'statusCode': 200, 'body': 'Cluster terminated'}\r``\n2. Step Functions Orchestration Workflow for complex data pipelines: json\r{\r\u0026quot;Comment\u0026quot;: \u0026quot;EMR Auto-scaling Pipeline\u0026quot;,\r\u0026quot;StartAt\u0026quot;: \u0026quot;CreateCluster\u0026quot;,\r\u0026quot;States\u0026quot;: {\r\u0026quot;CreateCluster\u0026quot;: {\r\u0026quot;Type\u0026quot;: \u0026quot;Task\u0026quot;,\r\u0026quot;Resource\u0026quot;: \u0026quot;arn:aws:states:::emr:createCluster.sync\u0026quot;,\r\u0026quot;Parameters\u0026quot;: {\r\u0026quot;Name\u0026quot;: \u0026quot;Pipeline-Cluster\u0026quot;,\r\u0026quot;ReleaseLabel\u0026quot;: \u0026quot;emr-6.15.0\u0026quot;\r},\r\u0026quot;Next\u0026quot;: \u0026quot;EnableScaling\u0026quot;\r},\r\u0026quot;EnableScaling\u0026quot;: {\r\u0026quot;Type\u0026quot;: \u0026quot;Task\u0026quot;,\r\u0026quot;Resource\u0026quot;: \u0026quot;arn:aws:states:::aws-sdk:emr:putManagedScalingPolicy\u0026quot;,\r\u0026quot;Parameters\u0026quot;: {\r\u0026quot;ClusterId.$\u0026quot;: \u0026quot;$.ClusterId\u0026quot;,\r\u0026quot;ManagedScalingPolicy\u0026quot;: {\r\u0026quot;ComputeLimits\u0026quot;: {\r\u0026quot;UnitType\u0026quot;: \u0026quot;Instances\u0026quot;,\r\u0026quot;MinimumCapacityUnits\u0026quot;: 2,\r\u0026quot;MaximumCapacityUnits\u0026quot;: 20\r}\r}\r},\r\u0026quot;Next\u0026quot;: \u0026quot;ProcessData\u0026quot;\r},\r\u0026quot;ProcessData\u0026quot;: {\r\u0026quot;Type\u0026quot;: \u0026quot;Task\u0026quot;,\r\u0026quot;Resource\u0026quot;: \u0026quot;arn:aws:states:::emr:addStep.sync\u0026quot;,\r\u0026quot;End\u0026quot;: true\r}\r}\r}\r3. EventBridge Rules Automatically respond to scaling events: json\r{\r\u0026quot;Rules\u0026quot;: [\r{\r\u0026quot;Name\u0026quot;: \u0026quot;EMR-ScaleOut-Alert\u0026quot;,\r\u0026quot;EventPattern\u0026quot;: {\r\u0026quot;source\u0026quot;: [\u0026quot;aws.emr\u0026quot;],\r\u0026quot;detail-type\u0026quot;: [\u0026quot;EMR Instance Group State Change\u0026quot;],\r\u0026quot;detail\u0026quot;: {\r\u0026quot;state\u0026quot;: [\u0026quot;RUNNING\u0026quot;],\r\u0026quot;requestedInstanceCount\u0026quot;: {\r\u0026quot;numeric\u0026quot;: [\u0026quot;\u0026gt;\u0026quot;, 5]\r}\r}\r},\r\u0026quot;Targets\u0026quot;: [\r{\r\u0026quot;Id\u0026quot;: \u0026quot;1\u0026quot;,\r\u0026quot;Arn\u0026quot;: \u0026quot;arn:aws:sns:us-east-1:123456789012:emr-alerts\u0026quot;\r}\r]\r}\r]\r}\rFinal Lab: End-to-End Scenario Scenario Setup Create a complete data processing pipeline:\nData Ingestion: S3 ‚Üí EMR Processing: Spark jobs with auto-scaling Output: Results ‚Üí S3 Monitoring: CloudWatch dashboard Cleanup: Automatic termination Implementation Steps Upload Sample Data: aws s3 cp sample-data.csv s3://your-bucket/input/\nCreate Processing Script: ``python\nend-to-end-pipeline.py from pyspark.sql import SparkSession from pyspark.sql.functions import *\nspark = SparkSession.builder.appName(\u0026ldquo;E2EPipeline\u0026rdquo;).getOrCreate()\nRead data from S3 df = spark.read.csv(\u0026ldquo;s3://your-bucket/input/sample-data.csv\u0026rdquo;, header=True)\nHeavy processing to trigger scaling df_processed = df.groupBy(\u0026ldquo;category\u0026rdquo;).agg( count(\u0026quot;*\u0026quot;).alias(\u0026ldquo;count\u0026rdquo;), avg(\u0026ldquo;value\u0026rdquo;).alias(\u0026ldquo;avg_value\u0026rdquo;), max(\u0026ldquo;value\u0026rdquo;).alias(\u0026ldquo;max_value\u0026rdquo;) ).repartition(50) # Force many partitions\nCache to consume memory df_processed.cache()\nMultiple operations result1 = df_processed.filter(col(\u0026ldquo;count\u0026rdquo;) \u0026gt; 100).count() result2 = df_processed.orderBy(desc(\u0026ldquo;avg_value\u0026rdquo;)).collect()\nWrite results df_processed.write.mode(\u0026ldquo;overwrite\u0026rdquo;).csv(\u0026ldquo;s3://your-bucket/output/\u0026rdquo;)\nprint(f\u0026quot;Pipeline completed. Processed {result1} categories\u0026quot;) spark.stop() ``\nSubmit Pipeline: aws emr add-steps --cluster-id j-xxxxx \\\r--steps '[{\r\u0026quot;Name\u0026quot;: \u0026quot;E2E-Pipeline\u0026quot;,\r\u0026quot;ActionOnFailure\u0026quot;: \u0026quot;TERMINATE_CLUSTER\u0026quot;,\r\u0026quot;HadoopJarStep\u0026quot;: {\r\u0026quot;Jar\u0026quot;: \u0026quot;command-runner.jar\u0026quot;,\r\u0026quot;Args\u0026quot;: [\r\u0026quot;spark-submit\u0026quot;,\r\u0026quot;--executor-memory\u0026quot;, \u0026quot;2g\u0026quot;,\r\u0026quot;--num-executors\u0026quot;, \u0026quot;20\u0026quot;,\r\u0026quot;s3://your-bucket/scripts/end-to-end-pipeline.py\u0026quot;\r]\r}\r}]'\nMonitor Complete Workflow:\nCluster starts with 3 instances Job begins, memory usage increases Auto-scaling kicks in, adds 4-6 instances Processing completes Scale-in begins, reduces to 3 instances Job finishes, cluster can terminate Expected Timeline 0-5 min: Job startup, initial processing 5-10 min: Heavy load, scaling out to 8-10 instances 10-25 min: Processing with full capacity 25-30 min: Job completion, scaling in 30-35 min: Final cleanup, cluster ready for next job Performance Metrics Analysis Key Performance Indicators (KPIs) Cost Efficiency:\nCost per GB processed Cost per job completion Utilization percentage Performance:\nJob completion time Throughput (GB/hour) Resource efficiency Reliability:\nSuccess rate Spot interruption impact Recovery time Benchmarking Results Static Cluster (Baseline):\n10 instances √ó 2 hours = 20 instance-hours Cost: $1.92 Processing time: 45 minutes Utilization: 60% Auto-Scaling Cluster: Average 6 instances √ó 2 hours = 12 instance-hours Cost: $1.15 Processing time: 50 minutes Utilization: 85% Improvement:\n40% cost reduction 25% better utilization Only 11% longer processing time Graduation Exercise Challenge: Optimize Real Workload You are provided with a 10GB dataset and requirements:\nProcess data with maximum budget of $2 Complete within 60 minutes Achieve 80%+ cluster utilization Handle at least 1 spot interruption Solution Approach Cluster Configuration: json\r{\r\u0026quot;InstanceGroups\u0026quot;: [\r{\r\u0026quot;Name\u0026quot;: \u0026quot;Master\u0026quot;,\r\u0026quot;InstanceRole\u0026quot;: \u0026quot;MASTER\u0026quot;, \u0026quot;InstanceType\u0026quot;: \u0026quot;m5.large\u0026quot;,\r\u0026quot;InstanceCount\u0026quot;: 1,\r\u0026quot;Market\u0026quot;: \u0026quot;ON_DEMAND\u0026quot;\r},\r{\r\u0026quot;Name\u0026quot;: \u0026quot;Core\u0026quot;,\r\u0026quot;InstanceRole\u0026quot;: \u0026quot;CORE\u0026quot;,\r\u0026quot;InstanceType\u0026quot;: \u0026quot;m5.large\u0026quot;, \u0026quot;InstanceCount\u0026quot;: 1,\r\u0026quot;Market\u0026quot;: \u0026quot;ON_DEMAND\u0026quot;\r},\r{\r\u0026quot;Name\u0026quot;: \u0026quot;Task\u0026quot;,\r\u0026quot;InstanceRole\u0026quot;: \u0026quot;TASK\u0026quot;,\r\u0026quot;InstanceType\u0026quot;: \u0026quot;m5.large\u0026quot;,\r\u0026quot;InstanceCount\u0026quot;: 0,\r\u0026quot;Market\u0026quot;: \u0026quot;SPOT\u0026quot;,\r\u0026quot;BidPrice\u0026quot;: \u0026quot;0.04\u0026quot;\r}\r]\r}\rScaling Policy: json\r{\r\u0026quot;ComputeLimits\u0026quot;: {\r\u0026quot;UnitType\u0026quot;: \u0026quot;Instances\u0026quot;,\r\u0026quot;MinimumCapacityUnits\u0026quot;: 2,\r\u0026quot;MaximumCapacityUnits\u0026quot;: 12,\r\u0026quot;MaximumOnDemandCapacityUnits\u0026quot;: 2,\r\u0026quot;MaximumCoreCapacityUnits\u0026quot;: 2\r}\r}\rOptimized Spark Job: ``python\noptimized-processing.py from pyspark.sql import SparkSession from pyspark.sql.functions import *\nspark = SparkSession.builder .appName(\u0026ldquo;OptimizedProcessing\u0026rdquo;) .config(\u0026ldquo;spark.sql.adaptive.enabled\u0026rdquo;, \u0026ldquo;true\u0026rdquo;) .config(\u0026ldquo;spark.sql.adaptive.coalescePartitions.enabled\u0026rdquo;, \u0026ldquo;true\u0026rdquo;) .config(\u0026ldquo;spark.serializer\u0026rdquo;, \u0026ldquo;org.apache.spark.serializer.KryoSerializer\u0026rdquo;) .getOrCreate()\nEfficient data reading df = spark.read.parquet(\u0026ldquo;s3://your-bucket/data/\u0026rdquo;) .repartition(100) # Optimal partitioning\nCheckpoint to handle spot interruptions spark.sparkContext.setCheckpointDir(\u0026ldquo;s3://your-bucket/checkpoints/\u0026rdquo;) df.checkpoint()\nProcessing with caching strategy df_processed = df.groupBy(\u0026ldquo;category\u0026rdquo;, \u0026ldquo;date\u0026rdquo;) .agg( sum(\u0026ldquo;amount\u0026rdquo;).alias(\u0026ldquo;total_amount\u0026rdquo;), count(\u0026quot;*\u0026quot;).alias(\u0026ldquo;transaction_count\u0026rdquo;), avg(\u0026ldquo;amount\u0026rdquo;).alias(\u0026ldquo;avg_amount\u0026rdquo;) ) .cache()\nMultiple outputs to maximize resource usage df_processed.write.mode(\u0026ldquo;overwrite\u0026rdquo;) .partitionBy(\u0026ldquo;date\u0026rdquo;) .parquet(\u0026ldquo;s3://your-bucket/output/summary/\u0026rdquo;)\ndf_processed.filter(col(\u0026ldquo;total_amount\u0026rdquo;) \u0026gt; 1000) .write.mode(\u0026ldquo;overwrite\u0026rdquo;) .json(\u0026ldquo;s3://your-bucket/output/high-value/\u0026rdquo;)\nspark.stop() ``\nSuccess Criteria Validation Cost Check: aws ce get-cost-and-usage \\\r--time-period Start=2024-01-01,End=2024-01-02 \\\r--granularity DAILY \\\r--metrics BlendedCost \\\r--group-by Type=DIMENSION,Key=SERVICE\nPerformance Check:\nMonitor job completion time Check cluster utilization metrics Verify data processing accuracy Reliability Check:\nSimulate spot interruption Verify job recovery Check data consistency Advanced Auto Scaling Techniques 1. Predictive Scaling with Machine Learning ``python\npredictive-scaling.py import boto3 import pandas as pd from sklearn.linear_model import LinearRegression import numpy as np\nclass PredictiveScaler: def init(self, cluster_id): self.cluster_id = cluster_id self.cloudwatch = boto3.client(\u0026lsquo;cloudwatch\u0026rsquo;) self.emr = boto3.client(\u0026rsquo;emr\u0026rsquo;)\ndef get_historical_metrics(self, days=30):\r# Get historical YARN metrics\rend_time = datetime.now()\rstart_time = end_time - timedelta(days=days)\rresponse = self.cloudwatch.get_metric_statistics(\rNamespace='AWS/ElasticMapReduce',\rMetricName='YARNMemoryAvailablePercentage',\rDimensions=[\r{'Name': 'JobFlowId', 'Value': self.cluster_id}\r],\rStartTime=start_time,\rEndTime=end_time,\rPeriod=3600,\rStatistics=['Average']\r)\rreturn response['Datapoints']\rdef predict_scaling_needs(self):\r# Simple ML model for prediction\rdata = self.get_historical_metrics()\rdf = pd.DataFrame(data)\rif len(df) \u0026lt; 24: # Need at least 24 hours of data\rreturn None\r# Feature engineering\rdf['hour'] = df['Timestamp'].dt.hour\rdf['day_of_week'] = df['Timestamp'].dt.dayofweek\r# Train model\rX = df[['hour', 'day_of_week']]\ry = df['Average']\rmodel = LinearRegression()\rmodel.fit(X, y)\r# Predict next hour\rnext_hour = datetime.now().hour + 1\rnext_day = datetime.now().weekday()\rpredicted_usage = model.predict([[next_hour, next_day]])[0]\r# Recommend scaling action\rif predicted_usage \u0026lt; 20: # Low memory available\rreturn 'scale_out'\relif predicted_usage \u0026gt; 80: # High memory available\rreturn 'scale_in'\relse:\rreturn 'no_action'\rdef apply_predictive_scaling(self):\raction = self.predict_scaling_needs()\rif action == 'scale_out':\r# Pre-emptively scale out\rself.emr.put_managed_scaling_policy(\rClusterId=self.cluster_id,\rManagedScalingPolicy={\r'ComputeLimits': {\r'UnitType': 'Instances',\r'MinimumCapacityUnits': 4, # Increase minimum\r'MaximumCapacityUnits': 15\r}\r}\r)\relif action == 'scale_in':\r# Allow more aggressive scale-in\rself.emr.put_managed_scaling_policy(\rClusterId=self.cluster_id,\rManagedScalingPolicy={\r'ComputeLimits': {\r'UnitType': 'Instances',\r'MinimumCapacityUnits': 2, # Reduce minimum\r'MaximumCapacityUnits': 10\r}\r}\r)\rUsage scaler = PredictiveScaler(\u0026lsquo;j-xxxxx\u0026rsquo;) scaler.apply_predictive_scaling() ``\n2. Multi-Cluster Auto Scaling For very large workloads, manage multiple clusters:\n``python\nmulti-cluster-manager.py import boto3 import json from datetime import datetime\nclass MultiClusterManager: def init(self): self.emr = boto3.client(\u0026rsquo;emr\u0026rsquo;) self.cloudwatch = boto3.client(\u0026lsquo;cloudwatch\u0026rsquo;) self.max_clusters = 3 self.cluster_template = { \u0026lsquo;Name\u0026rsquo;: \u0026lsquo;Auto-Cluster\u0026rsquo;, \u0026lsquo;ReleaseLabel\u0026rsquo;: \u0026rsquo;emr-6.15.0\u0026rsquo;, \u0026lsquo;Applications\u0026rsquo;: [{\u0026lsquo;Name\u0026rsquo;: \u0026lsquo;Spark\u0026rsquo;}], \u0026lsquo;ServiceRole\u0026rsquo;: \u0026lsquo;EMR_DefaultRole\u0026rsquo;, \u0026lsquo;JobFlowRole\u0026rsquo;: \u0026lsquo;EMR_EC2_DefaultRole\u0026rsquo; }\ndef get_active_clusters(self):\rresponse = self.emr.list_clusters(\rClusterStates=['STARTING', 'BOOTSTRAPPING', 'RUNNING', 'WAITING']\r)\rreturn [cluster for cluster in response['Clusters'] if 'Auto-Cluster' in cluster['Name']]\rdef get_cluster_load(self, cluster_id):\rtry:\rresponse = self.cloudwatch.get_metric_statistics(\rNamespace='AWS/ElasticMapReduce',\rMetricName='ContainerPending',\rDimensions=[{'Name': 'JobFlowId', 'Value': cluster_id}],\rStartTime=datetime.now() - timedelta(minutes=10),\rEndTime=datetime.now(),\rPeriod=300,\rStatistics=['Average']\r)\rif response['Datapoints']:\rreturn response['Datapoints'][-1]['Average']\rreturn 0\rexcept:\rreturn 0\rdef should_create_new_cluster(self):\ractive_clusters = self.get_active_clusters()\rif len(active_clusters) \u0026gt;= self.max_clusters:\rreturn False\r# Check if all clusters are heavily loaded\rtotal_pending = 0\rfor cluster in active_clusters:\rpending = self.get_cluster_load(cluster['Id'])\rtotal_pending += pending\r# Create new cluster if average pending \u0026gt; 10\ravg_pending = total_pending / len(active_clusters) if active_clusters else 0\rreturn avg_pending \u0026gt; 10\rdef create_cluster(self):\rresponse = self.emr.run_job_flow(\r**self.cluster_template,\rInstances={\r'MasterInstanceType': 'm5.large',\r'SlaveInstanceType': 'm5.large',\r'InstanceCount': 3,\r'Ec2KeyName': 'your-key',\r'InstanceGroups': [\r{\r'Name': 'Master',\r'InstanceRole': 'MASTER',\r'InstanceType': 'm5.large',\r'InstanceCount': 1,\r'Market': 'ON_DEMAND'\r},\r{\r'Name': 'Core',\r'InstanceRole': 'CORE',\r'InstanceType': 'm5.large',\r'InstanceCount': 2,\r'Market': 'SPOT',\r'BidPrice': '0.05'\r}\r]\r}\r)\rcluster_id = response['JobFlowId']\r# Enable auto-scaling on new cluster\rself.emr.put_managed_scaling_policy(\rClusterId=cluster_id,\rManagedScalingPolicy={\r'ComputeLimits': {\r'UnitType': 'Instances',\r'MinimumCapacityUnits': 3,\r'MaximumCapacityUnits': 10\r}\r}\r)\rreturn cluster_id\rdef terminate_idle_clusters(self):\ractive_clusters = self.get_active_clusters()\rfor cluster in active_clusters:\r# Check if cluster is idle\rsteps = self.emr.list_steps(\rClusterId=cluster['Id'],\rStepStates=['RUNNING', 'PENDING']\r)\rif not steps['Steps']:\r# No running steps, check idle time\rcluster_details = self.emr.describe_cluster(ClusterId=cluster['Id'])\rready_time = cluster_details['Cluster']['Status']['Timeline'].get('ReadyDateTime')\rif ready_time:\ridle_minutes = (datetime.now() - ready_time).total_seconds() / 60\rif idle_minutes \u0026gt; 30: # Idle for 30 minutes\rself.emr.terminate_job_flows(JobFlowIds=[cluster['Id']])\rprint(f\u0026quot;Terminated idle cluster: {cluster['Id']}\u0026quot;)\rdef manage_clusters(self):\r# Create new cluster if needed\rif self.should_create_new_cluster():\rnew_cluster = self.create_cluster()\rprint(f\u0026quot;Created new cluster: {new_cluster}\u0026quot;)\r# Terminate idle clusters\rself.terminate_idle_clusters()\rSchedule this to run every 5 minutes manager = MultiClusterManager() manager.manage_clusters() ``\n3. Cost-Aware Scaling Implement scaling that considers cost constraints:\n``python\ncost-aware-scaling.py import boto3 from datetime import datetime, timedelta\nclass CostAwareScaler: def init(self, cluster_id, daily_budget=50): self.cluster_id = cluster_id self.daily_budget = daily_budget self.emr = boto3.client(\u0026rsquo;emr\u0026rsquo;) self.ce = boto3.client(\u0026lsquo;ce\u0026rsquo;) self.cloudwatch = boto3.client(\u0026lsquo;cloudwatch\u0026rsquo;)\ndef get_current_spend(self):\rtoday = datetime.now().strftime('%Y-%m-%d')\rresponse = self.ce.get_cost_and_usage(\rTimePeriod={\r'Start': today,\r'End': today\r},\rGranularity='DAILY',\rMetrics=['BlendedCost'],\rGroupBy=[\r{'Type': 'DIMENSION', 'Key': 'SERVICE'}\r]\r)\remr_cost = 0\rfor result in response['ResultsByTime']:\rfor group in result['Groups']:\rif 'ElasticMapReduce' in group['Keys'][0]:\remr_cost += float(group['Metrics']['BlendedCost']['Amount'])\rreturn emr_cost\rdef calculate_hourly_cost(self):\rinstances = self.emr.list_instances(\rClusterId=self.cluster_id,\rInstanceStates=['RUNNING']\r)\rhourly_cost = 0\rfor instance in instances['Instances']:\rinstance_type = instance['InstanceType']\rmarket = instance.get('Market', 'ON_DEMAND')\r# Simplified cost calculation\rif 'm5.large' in instance_type:\rcost = 0.096 if market == 'ON_DEMAND' else 0.035\relif 'm5.xlarge' in instance_type:\rcost = 0.192 if market == 'ON_DEMAND' else 0.070\relse:\rcost = 0.1\rhourly_cost += cost\rreturn hourly_cost\rdef can_scale_out(self, additional_instances=1):\rcurrent_spend = self.get_current_spend()\rhourly_cost = self.calculate_hourly_cost()\r# Estimate cost for additional instances\rdef can_scale_out(self, additional_instances=1):\rcurrent_spend = self.get_current_spend()\rhourly_cost = self.calculate_hourly_cost()\r# Estimate cost for additional instances\radditional_cost = additional_instances * 0.035 # Spot price\rhours_remaining = 24 - datetime.now().hour\rprojected_spend = current_spend + (hourly_cost + additional_cost) * hours_remaining\rreturn projected_spend \u0026lt;= self.daily_budget * 0.9 # 90% of budget\rdef smart_scale_decision(self):\r# Get current metrics\rresponse = self.cloudwatch.get_metric_statistics(\rNamespace='AWS/ElasticMapReduce',\rMetricName='ContainerPending',\rDimensions=[{'Name': 'JobFlowId', 'Value': self.cluster_id}],\rStartTime=datetime.now() - timedelta(minutes=10),\rEndTime=datetime.now(),\rPeriod=300,\rStatistics=['Average']\r)\rpending_containers = 0\rif response['Datapoints']:\rpending_containers = response['Datapoints'][-1]['Average']\r# Scale out decision\rif pending_containers \u0026gt; 5 and self.can_scale_out():\rreturn 'scale_out'\relif pending_containers == 0:\rreturn 'scale_in'\relse:\rreturn 'no_action'\rdef apply_cost_aware_scaling(self):\rdecision = self.smart_scale_decision()\rcurrent_spend = self.get_current_spend()\rbudget_used = (current_spend / self.daily_budget) * 100\rprint(f\u0026quot;Budget used: {budget_used:.1f}%\u0026quot;)\rprint(f\u0026quot;Scaling decision: {decision}\u0026quot;)\rif decision == 'scale_out' and budget_used \u0026lt; 80:\r# Conservative scaling when budget is tight\rmax_capacity = 15 if budget_used \u0026lt; 50 else 8\rself.emr.put_managed_scaling_policy(\rClusterId=self.cluster_id,\rManagedScalingPolicy={\r'ComputeLimits': {\r'UnitType': 'Instances',\r'MinimumCapacityUnits': 3,\r'MaximumCapacityUnits': max_capacity\r}\r}\r)\relif decision == 'scale_in' or budget_used \u0026gt; 90:\r# Aggressive scale-in when over budget\rself.emr.put_managed_scaling_policy(\rClusterId=self.cluster_id,\rManagedScalingPolicy={\r'ComputeLimits': {\r'UnitType': 'Instances',\r'MinimumCapacityUnits': 2,\r'MaximumCapacityUnits': 5\r}\r}\r)\rUsage scaler = CostAwareScaler(\u0026lsquo;j-xxxxx\u0026rsquo;, daily_budget=100) scaler.apply_cost_aware_scaling() ``\nProduction Deployment Checklist Pre-Deployment IAM roles configured with proper permissions VPC and security groups set up S3 buckets created for data and logs CloudWatch alarms configured SNS topics for notifications Lambda functions for automation Scaling Configuration Minimum capacity set to handle baseline load Maximum capacity set within budget constraints Cooldown periods optimized for workload Instance types diversified for availability Spot/On-Demand mix configured Monitoring Setup CloudWatch dashboard created Cost tracking enabled Performance metrics monitored Alert thresholds configured Log aggregation set up Testing Validation Scale-out tested with heavy workload Scale-in tested with light workload Spot interruption handling verified Cost limits enforced Performance benchmarks established Conclusion Part 2 What You\u0026rsquo;ve Accomplished: ‚úÖ EMR Managed Scaling: Set up and configured successfully ‚úÖ Cost Optimization: Achieved 40% cost reduction with dynamic scaling ‚úÖ Performance Tuning: Optimized Spark for auto-scaling environment ‚úÖ Monitoring: Set up scaling events and metrics tracking ‚úÖ Troubleshooting: Learned to handle common scaling issues ‚úÖ Production Patterns: Implemented best practices for real-world usage Cost Savings Summary: Part 1 (Spot): 39% savings Part 2 (Auto Scaling): 40% additional savings Combined: ~65% total cost reduction compared to static On-Demand cluster Key Takeaways: Auto-scaling works best with: Predictable workload patterns, proper monitoring, and cost constraints Spot + Auto-scaling combination: Provides maximum cost efficiency Monitoring is critical: For troubleshooting and optimization Application design matters: Stateless, fault-tolerant applications scale better Real-World Impact: Small company (10 clusters): $2,000/month ‚Üí $700/month = $1,300 saved Medium company (50 clusters): $10,000/month ‚Üí $3,500/month = $6,500 saved Large enterprise (200 clusters): $40,000/month ‚Üí $14,000/month = $26,000 saved Next Steps: In Part 3, we\u0026rsquo;ll set up comprehensive monitoring and alerting to ensure your optimized clusters run smoothly and cost-effectively in production.\nPro Tip: In production, combine auto-scaling with scheduled scaling for predictable workloads to achieve maximum 70-80% cost savings!\nNext: Part 3: Monitoring \u0026amp; Alerting to complete your cost optimization journey.\n"
},
{
	"uri": "https://banh251o.github.io/EMR-Cost-Optimization-Workshop/3-mornitoring/",
	"title": "Part 3: Monitoring &amp; Alerting",
	"tags": [],
	"description": "",
	"content": "Part 3: EMR Monitoring \u0026amp; Alerting - Complete Observability In this final section, you\u0026rsquo;ll set up comprehensive monitoring and alerting for your cost-optimized EMR clusters to ensure they run efficiently and within budget in production.\nWhat You\u0026rsquo;ll Learn Real-time monitoring of EMR clusters and costs Proactive alerting for performance and cost issues Custom dashboards for different stakeholders Automated remediation for common problems Cost tracking and optimization recommendations Monitoring Architecture Overview Core Monitoring Components 1. EMR Native Metrics Cluster-level metrics:\nYARNMemoryAvailablePercentage ContainerAllocated/Pending AppsCompleted/Failed/Running TotalNodesRunning Instance-level metrics:\nCPU Utilization Memory Utilization Disk I/O Network I/O 2. Cost Metrics Real-time cost tracking:\nHourly spend rate Daily budget consumption Cost per job/application Spot vs On-Demand usage 3. Application Metrics Spark application metrics:\nJob execution time Stage completion rates Executor failures Data processing throughput Hands-on: Complete Monitoring Setup Step 1: Enable Enhanced Monitoring Open EMR Console Select your cluster from Parts 1 \u0026amp; 2 Go to Configuration tab Enable detailed monitoring CLI Method:\naws emr modify-cluster \\ --cluster-id j-xxxxx \\ --step-concurrency-level 10 \\ --visible-to-all-users Step 2:Create SNS Topics for Alerts Create different severity topics aws sns create-topic \u0026ndash;name emr-critical-alerts aws sns create-topic \u0026ndash;name emr-warning-alerts\naws sns create-topic \u0026ndash;name emr-info-alerts aws sns create-topic \u0026ndash;name emr-cost-alerts\nSubscribe to email notifications aws sns subscribe \\ --topic-arn arn:aws:sns:us-east-1:123456789012:emr-critical-alerts \\ --protocol email \\ --notification-endpoint your-email@company.com Step 3:Complete Monitoring Solution ``python complete-emr-monitoring.py import boto3 import json from datetime import datetime, timedelta import time\nclass EMRMonitoringSystem: def init(self, cluster_id, daily_budget=100): self.cluster_id = cluster_id self.daily_budget = daily_budget self.emr = boto3.client(\u0026rsquo;emr\u0026rsquo;) self.cloudwatch = boto3.client(\u0026lsquo;cloudwatch\u0026rsquo;) self.sns = boto3.client(\u0026lsquo;sns\u0026rsquo;) self.ce = boto3.client(\u0026lsquo;ce\u0026rsquo;) # SNS Topic ARNs self.topics = { \u0026lsquo;critical\u0026rsquo;: \u0026lsquo;arn:aws:sns:us-east-1:123456789012:emr-critical-alerts\u0026rsquo;, \u0026lsquo;warning\u0026rsquo;: \u0026lsquo;arn:aws:sns:us-east-1:123456789012:emr-warning-alerts\u0026rsquo;, \u0026lsquo;info\u0026rsquo;: \u0026lsquo;arn:aws:sns:us-east-1:123456789012:emr-info-alerts\u0026rsquo;, \u0026lsquo;cost\u0026rsquo;: \u0026lsquo;arn:aws:sns:us-east-1:123456789012:emr-cost-alerts\u0026rsquo; }\ndef setup_sns_topics(self): \u0026ldquo;\u0026ldquo;\u0026ldquo;Create SNS topics for different alert types\u0026rdquo;\u0026rdquo;\u0026rdquo; topics_to_create = [\u0026rsquo;emr-critical-alerts\u0026rsquo;, \u0026rsquo;emr-warning-alerts\u0026rsquo;, \u0026rsquo;emr-info-alerts\u0026rsquo;, \u0026rsquo;emr-cost-alerts\u0026rsquo;]\nfor topic_name in topics_to_create:\rtry:\rresponse = self.sns.create_topic(Name=topic_name)\rprint(f\u0026quot;Created SNS topic: {topic_name}\u0026quot;)\rprint(f\u0026quot;Topic ARN: {response['TopicArn']}\u0026quot;)\rexcept Exception as e:\rprint(f\u0026quot;Error creating topic {topic_name}: {e}\u0026quot;)\rdef calculate_current_cost(self): \u0026ldquo;\u0026ldquo;\u0026ldquo;Calculate real-time cluster cost\u0026rdquo;\u0026rdquo;\u0026rdquo; try: instances = self.emr.list_instances( ClusterId=self.cluster_id, InstanceStates=[\u0026lsquo;RUNNING\u0026rsquo;] )\ntotal_hourly_cost = 0\rinstance_breakdown = []\r# Cost mapping (simplified)\rcost_map = {\r'm5.large': {'ON_DEMAND': 0.096, 'SPOT': 0.035},\r'm5.xlarge': {'ON_DEMAND': 0.192, 'SPOT': 0.070},\r'm5.2xlarge': {'ON_DEMAND': 0.384, 'SPOT': 0.140},\r'm4.large': {'ON_DEMAND': 0.100, 'SPOT': 0.040},\r'c5.large': {'ON_DEMAND': 0.085, 'SPOT': 0.030}\r}\rfor instance in instances['Instances']:\rinstance_type = instance['InstanceType']\rmarket = instance.get('Market', 'ON_DEMAND')\rhourly_cost = cost_map.get(instance_type, {}).get(market, 0.1)\rtotal_hourly_cost += hourly_cost\rinstance_breakdown.append({\r'InstanceId': instance['Id'],\r'InstanceType': instance_type,\r'Market': market,\r'HourlyCost': hourly_cost,\r'State': instance['Status']['State']\r})\rreturn total_hourly_cost, instance_breakdown\rexcept Exception as e:\rprint(f\u0026quot;Error calculating cost: {e}\u0026quot;)\rreturn 0, []\rdef get_cluster_metrics(self): \u0026ldquo;\u0026ldquo;\u0026ldquo;Get current cluster performance metrics\u0026rdquo;\u0026rdquo;\u0026rdquo; try: end_time = datetime.utcnow() start_time = end_time - timedelta(minutes=10)\nmetrics_to_get = [\r'YARNMemoryAvailablePercentage',\r'ContainerPending',\r'AppsRunning',\r'AppsFailed',\r'TotalNodesRunning'\r]\rmetrics_data = {}\rfor metric_name in metrics_to_get:\rresponse = self.cloudwatch.get_metric_statistics(\rNamespace='AWS/ElasticMapReduce',\rMetricName=metric_name,\rDimensions=[\r{'Name': 'JobFlowId', 'Value': self.cluster_id}\r],\rStartTime=start_time,\rEndTime=end_time,\rPeriod=300,\rStatistics=['Average', 'Maximum']\r)\rif response['Datapoints']:\rlatest_datapoint = max(response['Datapoints'], key=lambda x: x['Timestamp'])\rmetrics_data[metric_name] = {\r'Average': latest_datapoint.get('Average', 0),\r'Maximum': latest_datapoint.get('Maximum', 0),\r'Timestamp': latest_datapoint['Timestamp']\r}\relse:\rmetrics_data[metric_name] = {'Average': 0, 'Maximum': 0, 'Timestamp': datetime.utcnow()}\rreturn metrics_data\rexcept Exception as e:\rprint(f\u0026quot;Error getting metrics: {e}\u0026quot;)\rreturn {}\rdef get_daily_cost(self):\r\u0026quot;\u0026quot;\u0026quot;Get today's EMR cost from Cost Explorer\u0026quot;\u0026quot;\u0026quot;\rtry:\rtoday = datetime.now().strftime('%Y-%m-%d')\rtomorrow = (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d')\rresponse = self.ce.get_cost_and_usage(\rTimePeriod={'Start': today, 'End': tomorrow},\rGranularity='DAILY',\rMetrics=['BlendedCost'],\rGroupBy=[{'Type': 'DIMENSION', 'Key': 'SERVICE'}]\r)\remr_cost = 0\rfor result in response['ResultsByTime']:\rfor group in result['Groups']:\rif 'ElasticMapReduce' in group['Keys'][0]:\remr_cost += float(group['Metrics']['BlendedCost']['Amount'])\rreturn emr_cost\rexcept Exception as e:\rprint(f\u0026quot;Error getting daily cost: {e}\u0026quot;)\rreturn 0\rdef publish_custom_metrics(self):\r\u0026quot;\u0026quot;\u0026quot;Publish custom metrics to CloudWatch\u0026quot;\u0026quot;\u0026quot;\rtry:\rhourly_cost, instance_breakdown = self.calculate_current_cost()\rdaily_cost = self.get_daily_cost()\rcluster_metrics = self.get_cluster_metrics()\r# Publish cost metrics\rmetric_data = [\r{\r'MetricName': 'HourlyCost',\r'Dimensions': [{'Name': 'ClusterId', 'Value': self.cluster_id}],\r'Value': hourly_cost,\r'Unit': 'None',\r'Timestamp': datetime.utcnow()\r},\r{\r'MetricName': 'DailyCost',\r'Dimensions': [{'Name': 'ClusterId', 'Value': self.cluster_id}],\r'Value': daily_cost,\r'Unit': 'None',\r'Timestamp': datetime.utcnow()\r},\r{\r'MetricName': 'BudgetUtilization',\r'Dimensions': [{'Name': 'ClusterId', 'Value': self.cluster_id}],\r'Value': (daily_cost / self.daily_budget) * 100,\r'Unit': 'Percent',\r'Timestamp': datetime.utcnow()\r},\r{\r'MetricName': 'RunningInstances',\r'Dimensions': [{'Name': 'ClusterId', 'Value': self.cluster_id}],\r'Value': len(instance_breakdown),\r'Unit': 'Count',\r'Timestamp': datetime.utcnow()\r}\r]\r# Add spot vs on-demand breakdown\rspot_instances = sum(1 for inst in instance_breakdown if inst['Market'] == 'SPOT')\rondemand_instances = len(instance_breakdown) - spot_instances\rmetric_data.extend([\r{\r'MetricName': 'SpotInstances',\r'Dimensions': [{'Name': 'ClusterId', 'Value': self.cluster_id}],\r'Value': spot_instances,\r'Unit': 'Count',\r'Timestamp': datetime.utcnow()\r},\r{\r'MetricName': 'OnDemandInstances',\r'Dimensions': [{'Name': 'ClusterId', 'Value': self.cluster_id}],\r'Value': ondemand_instances,\r'Unit': 'Count',\r'Timestamp': datetime.utcnow()\r}\r])\r# Publish metrics in batches (CloudWatch limit is 20 per call)\rfor i in range(0, len(metric_data), 20):\rbatch = metric_data[i:i+20]\rself.cloudwatch.put_metric_data(\rNamespace='EMR/CostOptimization',\rMetricData=batch\r)\rprint(f\u0026quot;Published {len(metric_data)} custom metrics\u0026quot;)\rreturn True\rexcept Exception as e:\rprint(f\u0026quot;Error publishing metrics: {e}\u0026quot;)\rreturn False\rdef create_cloudwatch_alarms(self):\r\u0026quot;\u0026quot;\u0026quot;Create comprehensive CloudWatch alarms\u0026quot;\u0026quot;\u0026quot;\ralarms = [\r# Critical Performance Alarms\r{\r'AlarmName': f'EMR-{self.cluster_id}-CriticalMemoryUsage',\r'ComparisonOperator': 'LessThanThreshold',\r'EvaluationPeriods': 2,\r'MetricName': 'YARNMemoryAvailablePercentage',\r'Namespace': 'AWS/ElasticMapReduce',\r'Period': 300,\r'Statistic': 'Average',\r'Threshold': 5.0,\r'ActionsEnabled': True,\r'AlarmActions': [self.topics['critical']],\r'AlarmDescription': 'Critical: Memory usage extremely high',\r'Dimensions': [{'Name': 'JobFlowId', 'Value': self.cluster_id}],\r'TreatMissingData': 'breaching'\r},\r{\r'AlarmName': f'EMR-{self.cluster_id}-JobFailures',\r'ComparisonOperator': 'GreaterThanThreshold',\r'EvaluationPeriods': 1,\r'MetricName': 'AppsFailed',\r'Namespace': 'AWS/ElasticMapReduce',\r'Period': 300,\r'Statistic': 'Sum',\r'Threshold': 2.0,\r'ActionsEnabled': True,\r'AlarmActions': [self.topics['critical']],\r'AlarmDescription': 'Critical: Multiple job failures',\r'Dimensions': [{'Name': 'JobFlowId', 'Value': self.cluster_id}],\r'TreatMissingData': 'notBreaching'\r},\r{\r'AlarmName': f'EMR-{self.cluster_id}-ClusterDown',\r'ComparisonOperator': 'LessThanThreshold',\r'EvaluationPeriods': 2,\r'MetricName': 'TotalNodesRunning',\r'Namespace': 'AWS/ElasticMapReduce',\r'Period': 300,\r'Statistic': 'Average',\r'Threshold': 2.0,\r'ActionsEnabled': True,\r'AlarmActions': [self.topics['critical']],\r'AlarmDescription': 'Critical: Cluster nodes critically low',\r'Dimensions': [{'Name': 'JobFlowId', 'Value': self.cluster_id}],\r'TreatMissingData': 'breaching'\r},\r# Warning Performance Alarms\r{\r'AlarmName': f'EMR-{self.cluster_id}-HighMemoryUsage',\r'ComparisonOperator': 'LessThanThreshold',\r'EvaluationPeriods': 3,\r'MetricName': 'YARNMemoryAvailablePercentage',\r'Namespace': 'AWS/ElasticMapReduce',\r'Period': 300,\r'Statistic': 'Average',\r'Threshold': 20.0,\r'ActionsEnabled': True,\r'AlarmActions': [self.topics['warning']],\r'AlarmDescription': 'Warning: Memory usage high',\r'Dimensions': [{'Name': 'JobFlowId', 'Value': self.cluster_id}],\r'TreatMissingData': 'notBreaching'\r},\r{\r'AlarmName': f'EMR-{self.cluster_id}-PendingContainers',\r'ComparisonOperator': 'GreaterThanThreshold',\r'EvaluationPeriods': 3,\r'MetricName': 'ContainerPending',\r'Namespace': 'AWS/ElasticMapReduce',\r'Period': 300,\r'Statistic': 'Average',\r'Threshold': 10.0,\r'ActionsEnabled': True,\r'AlarmActions': [self.topics['warning']],\r'AlarmDescription': 'Warning: Many containers pending',\r'Dimensions': [{'Name': 'JobFlowId', 'Value': self.cluster_id}],\r'TreatMissingData': 'notBreaching'\r},\r# Cost Alarms\r{\r'AlarmName': f'EMR-{self.cluster_id}-HourlyCostHigh',\r'ComparisonOperator': 'GreaterThanThreshold',\r'EvaluationPeriods': 1,\r'MetricName': 'HourlyCost',\r'Namespace': 'EMR/CostOptimization',\r'Period': 3600,\r'Statistic': 'Average',\r'Threshold': self.daily_budget / 8, # 1/8 of daily budget per hour\r'ActionsEnabled': True,\r'AlarmActions': [self.topics['cost']],\r'AlarmDescription': 'Cost: Hourly cost exceeding budget',\r'Dimensions': [{'Name': 'ClusterId', 'Value': self.cluster_id}],\r'TreatMissingData': 'notBreaching'\r},\r{\r'AlarmName': f'EMR-{self.cluster_id}-BudgetExceeded',\r'ComparisonOperator': 'GreaterThanThreshold',\r'EvaluationPeriods': 1,\r'MetricName': 'BudgetUtilization',\r'Namespace': 'EMR/CostOptimization',\r'Period': 3600,\r'Statistic': 'Average',\r'Threshold': 90.0,\r'ActionsEnabled': True,\r'AlarmActions': [self.topics['cost']],\r'AlarmDescription': 'Cost: Daily budget 90% exceeded',\r'Dimensions': [{'Name': 'ClusterId', 'Value': self.cluster_id}],\r'TreatMissingData': 'notBreaching'\r}\r]\r# Create all alarms\rfor alarm in alarms:\rtry:\rself.cloudwatch.put_metric_alarm(**alarm)\rprint(f\u0026quot;Created alarm: {alarm['AlarmName']}\u0026quot;)\rexcept Exception as e:\rprint(f\u0026quot;Error creating alarm {alarm['AlarmName']}: {e}\u0026quot;)\rdef create_dashboard(self):\r\u0026quot;\u0026quot;\u0026quot;Create comprehensive CloudWatch dashboard\u0026quot;\u0026quot;\u0026quot;\rdashboard_body = {\r\u0026quot;widgets\u0026quot;: [\r{\r\u0026quot;type\u0026quot;: \u0026quot;metric\u0026quot;,\r\u0026quot;x\u0026quot;: 0, \u0026quot;y\u0026quot;: 0, \u0026quot;width\u0026quot;: 12, \u0026quot;height\u0026quot;: 6,\r\u0026quot;properties\u0026quot;: {\r\u0026quot;metrics\u0026quot;: [\r[\u0026quot;AWS/ElasticMapReduce\u0026quot;, \u0026quot;YARNMemoryAvailablePercentage\u0026quot;, \u0026quot;JobFlowId\u0026quot;, self.cluster_id],\r[\u0026quot;.\u0026quot;, \u0026quot;ContainerPending\u0026quot;, \u0026quot;.\u0026quot;, \u0026quot;.\u0026quot;],\r[\u0026quot;.\u0026quot;, \u0026quot;AppsRunning\u0026quot;, \u0026quot;.\u0026quot;, \u0026quot;.\u0026quot;]\r],\r\u0026quot;view\u0026quot;: \u0026quot;timeSeries\u0026quot;,\r\u0026quot;stacked\u0026quot;: False,\r\u0026quot;region\u0026quot;: \u0026quot;us-east-1\u0026quot;,\r\u0026quot;title\u0026quot;: \u0026quot;Cluster Performance Metrics\u0026quot;,\r\u0026quot;period\u0026quot;: 300\r}\r},\r{\r\u0026quot;type\u0026quot;: \u0026quot;metric\u0026quot;,\r\u0026quot;x\u0026quot;: 12, \u0026quot;y\u0026quot;: 0, \u0026quot;width\u0026quot;: 12, \u0026quot;height\u0026quot;: 6,\r\u0026quot;properties\u0026quot;: {\r\u0026quot;metrics\u0026quot;: [\r[\u0026quot;EMR/CostOptimization\u0026quot;, \u0026quot;HourlyCost\u0026quot;, \u0026quot;ClusterId\u0026quot;, self.cluster_id],\r[\u0026quot;.\u0026quot;, \u0026quot;DailyCost\u0026quot;, \u0026quot;.\u0026quot;, \u0026quot;.\u0026quot;],\r[\u0026quot;.\u0026quot;, \u0026quot;BudgetUtilization\u0026quot;, \u0026quot;.\u0026quot;, \u0026quot;.\u0026quot;]\r],\r\u0026quot;view\u0026quot;: \u0026quot;timeSeries\u0026quot;,\r\u0026quot;stacked\u0026quot;: False,\r\u0026quot;region\u0026quot;: \u0026quot;us-east-1\u0026quot;,\r\u0026quot;title\u0026quot;: \u0026quot;Cost Metrics\u0026quot;,\r\u0026quot;period\u0026quot;: 3600\r}\r},\r{\r\u0026quot;type\u0026quot;: \u0026quot;metric\u0026quot;,\r\u0026quot;x\u0026quot;: 0, \u0026quot;y\u0026quot;: 6, \u0026quot;width\u0026quot;: 12, \u0026quot;height\u0026quot;: 6,\r\u0026quot;properties\u0026quot;: {\r\u0026quot;metrics\u0026quot;: [\r[\u0026quot;EMR/CostOptimization\u0026quot;, \u0026quot;RunningInstances\u0026quot;, \u0026quot;ClusterId\u0026quot;, self.cluster_id],\r[\u0026quot;.\u0026quot;, \u0026quot;SpotInstances\u0026quot;, \u0026quot;.\u0026quot;, \u0026quot;.\u0026quot;],\r[\u0026quot;.\u0026quot;, \u0026quot;OnDemandInstances\u0026quot;, \u0026quot;.\u0026quot;, \u0026quot;.\u0026quot;]\r],\r\u0026quot;view\u0026quot;: \u0026quot;timeSeries\u0026quot;,\r\u0026quot;stacked\u0026quot;: True,\r\u0026quot;region\u0026quot;: \u0026quot;us-east-1\u0026quot;,\r\u0026quot;title\u0026quot;: \u0026quot;Instance Count \u0026amp; Mix\u0026quot;,\r\u0026quot;period\u0026quot;: 300\r}\r},\r{\r\u0026quot;type\u0026quot;: \u0026quot;log\u0026quot;,\r\u0026quot;x\u0026quot;: 12, \u0026quot;y\u0026quot;: 6, \u0026quot;width\u0026quot;: 12, \u0026quot;height\u0026quot;: 6,\r\u0026quot;properties\u0026quot;: {\r\u0026quot;query\u0026quot;: f\u0026quot;SOURCE '/aws/emr/{self.cluster_id}/step' | fields @timestamp, @message\\n| filter @message like /ERROR/\\n| sort @timestamp desc\\n| limit 20\u0026quot;,\r\u0026quot;region\u0026quot;: \u0026quot;us-east-1\u0026quot;,\r\u0026quot;title\u0026quot;: \u0026quot;Recent Errors\u0026quot;,\r\u0026quot;view\u0026quot;: \u0026quot;table\u0026quot;\r}\r}\r]\r}\rtry:\rself.cloudwatch.put_dashboard(\rDashboardName=f'EMR-{self.cluster_id}-Monitoring',\rDashboardBody=json.dumps(dashboard_body)\r)\rprint(f\u0026quot;Created dashboard: EMR-{self.cluster_id}-Monitoring\u0026quot;)\rexcept Exception as e:\rprint(f\u0026quot;Error creating dashboard: {e}\u0026quot;)\rdef send_alert(self, severity, message, details=None):\r\u0026quot;\u0026quot;\u0026quot;Send alert to appropriate SNS topic\u0026quot;\u0026quot;\u0026quot;\rtry:\rtopic_arn = self.topics.get(severity, self.topics['info'])\ralert_message = {\r'ClusterId': self.cluster_id,\r'Severity': severity.upper(),\r'Message': message,\r'Timestamp': datetime.utcnow().isoformat(),\r'Details': details or {}\r}\rself.sns.publish(\rTopicArn=topic_arn,\rMessage=json.dumps(alert_message, indent=2),\rSubject=f'EMR Alert [{severity.upper()}]: {self.cluster_id}'\r)\rprint(f\u0026quot;Sent {severity} alert: {message}\u0026quot;)\rexcept Exception as e:\rprint(f\u0026quot;Error sending alert: {e}\u0026quot;)\rdef check_cluster_health(self):\r\u0026quot;\u0026quot;\u0026quot;Comprehensive cluster health check\u0026quot;\u0026quot;\u0026quot;\rtry:\r# Get cluster details\rcluster_details = self.emr.describe_cluster(ClusterId=self.cluster_id)\rcluster_state = cluster_details['Cluster']['Status']['State']\r# Get metrics\rmetrics = self.get_cluster_metrics()\rhourly_cost, instances = self.calculate_current_cost()\rdaily_cost = self.get_daily_cost()\rhealth_report = {\r'cluster_state': cluster_state,\r'total_instances': len(instances),\r'hourly_cost': hourly_cost,\r'daily_cost': daily_cost,\r'budget_utilization': (daily_cost / self.daily_budget) * 100,\r'memory_available': metrics.get('YARNMemoryAvailablePercentage', {}).get('Average', 0),\r'pending_containers': metrics.get('ContainerPending', {}).get('Average', 0),\r'running_apps': metrics.get('AppsRunning', {}).get('Average', 0),\r'failed_apps': metrics.get('AppsFailed', {}).get('Average', 0)\r}\r# Health checks\rissues = []\rif cluster_state not in ['RUNNING', 'WAITING']:\rissues.append(f\u0026quot;Cluster state is {cluster_state}\u0026quot;)\rif health_report['memory_available'] \u0026lt; 10:\rissues.append(f\u0026quot;Critical memory usage: {health_report['memory_available']:.1f}% available\u0026quot;)\rif health_report['pending_containers'] \u0026gt; 20:\rissues.append(f\u0026quot;High container queue: {health_report['pending_containers']:.0f} pending\u0026quot;)\rif health_report['budget_utilization'] \u0026gt; 90:\rissues.append(f\u0026quot;Budget exceeded: {health_report['budget_utilization']:.1f}% used\u0026quot;)\rif health_report['failed_apps'] \u0026gt; 0:\rissues.append(f\u0026quot;Application failures: {health_report['failed_apps']:.0f} failed apps\u0026quot;)\r# Send alerts based on issues\rif issues:\rseverity = 'critical' if any('Critical' in issue or 'exceeded' in issue for issue in issues) else 'warning'\rself.send_alert(\rseverity=severity,\rmessage=f\u0026quot;Cluster health issues detected: {len(issues)} problems\u0026quot;,\rdetails={'issues': issues, 'health_report': health_report}\r)\rreturn health_report, issues\rexcept Exception as e:\rprint(f\u0026quot;Error checking cluster health: {e}\u0026quot;)\rreturn {}, [f\u0026quot;Health check failed: {e}\u0026quot;]\rdef automated_remediation(self):\r\u0026quot;\u0026quot;\u0026quot;Attempt automated fixes for common issues\u0026quot;\u0026quot;\u0026quot;\rtry:\rhealth_report, issues = self.check_cluster_health()\rremediation_actions = []\r# Auto-scaling remediation\rif health_report.get('memory_available', 100) \u0026lt; 15 and health_report.get('pending_containers', 0) \u0026gt; 10:\rtry:\r# Increase max capacity temporarily\rself.emr.put_managed_scaling_policy(\rClusterId=self.cluster_id,\rManagedScalingPolicy={\r'ComputeLimits': {\r'UnitType': 'Instances',\r'MinimumCapacityUnits': 3,\r'MaximumCapacityUnits': 20 # Temporary increase\r}\r}\r)\rremediation_actions.append(\u0026quot;Increased max cluster capacity to handle load\u0026quot;)\rexcept Exception as e:\rremediation_actions.append(f\u0026quot;Failed to increase capacity: {e}\u0026quot;)\r# Cost remediation\rif health_report.get('budget_utilization', 0) \u0026gt; 95:\rtry:\r# Reduce max capacity to control costs\rself.emr.put_managed_scaling_policy(\rClusterId=self.cluster_id,\rManagedScalingPolicy={\r'ComputeLimits': {\r'UnitType': 'Instances',\r'MinimumCapacityUnits': 2,\r'MaximumCapacityUnits': 5 # Reduce to save costs\r}\r}\r)\rremediation_actions.append(\u0026quot;Reduced max capacity due to budget constraints\u0026quot;)\rexcept Exception as e:\rremediation_actions.append(f\u0026quot;Failed to reduce capacity: {e}\u0026quot;)\rif remediation_actions:\rself.send_alert(\rseverity='info',\rmessage=f\u0026quot;Automated remediation applied: {len(remediation_actions)} actions\u0026quot;,\rdetails={'actions': remediation_actions}\r)\rreturn remediation_actions\rexcept Exception as e:\rprint(f\u0026quot;Error in automated remediation: {e}\u0026quot;)\rreturn []\rdef generate_cost_report(self):\r\u0026quot;\u0026quot;\u0026quot;Generate detailed cost analysis report\u0026quot;\u0026quot;\u0026quot;\rtry:\rhourly_cost, instances = self.calculate_current_cost()\rdaily_cost = self.get_daily_cost()\r# Instance breakdown\rinstance_summary = {}\rfor instance in instances:\rkey = f\u0026quot;{instance['InstanceType']}-{instance['Market']}\u0026quot;\rif key not in instance_summary:\rinstance_summary[key] = {'count': 0, 'total_cost': 0}\rinstance_summary[key]['count'] += 1\rinstance_summary[key]['total_cost'] += instance['HourlyCost']\r# Cost projections\rprojected_daily = hourly_cost * 24\rprojected_monthly = projected_daily * 30\rcost_report = {\r'timestamp': datetime.utcnow().isoformat(),\r'cluster_id': self.cluster_id,\r'current_metrics': {\r'hourly_cost': round(hourly_cost, 3),\r'daily_cost': round(daily_cost, 2),\r'budget_utilization': round((daily_cost / self.daily_budget) * 100, 1),\r'total_instances': len(instances)\r},\r'projections': {\r'projected_daily': round(projected_daily, 2),\r'projected_monthly': round(projected_monthly, 2),\r'days_until_budget_exceeded': round(self.daily_budget / projected_daily, 1) if projected_daily \u0026gt; 0 else float('inf')\r},\r'instance_breakdown': instance_summary,\r'cost_optimization_tips': []\r}\r# Generate optimization recommendations\rspot_percentage = sum(1 for inst in instances if inst['Market'] == 'SPOT') / len(instances) * 100 if instances else 0\rif spot_percentage \u0026lt; 70:\rcost_report['cost_optimization_tips'].append(f\u0026quot;Increase Spot usage: Currently {spot_percentage:.1f}%, target 70%+\u0026quot;)\rif projected_daily \u0026gt; self.daily_budget:\rcost_report['cost_optimization_tips'].append(f\u0026quot;Reduce cluster size: Projected daily cost ${projected_daily:.2f} exceeds budget ${self.daily_budget}\u0026quot;)\rif len(instances) \u0026gt; 10:\rcost_report['cost_optimization_tips'].append(\u0026quot;Consider using larger instance types to reduce overhead\u0026quot;)\rreturn cost_report\rexcept Exception as e:\rprint(f\u0026quot;Error generating cost report: {e}\u0026quot;)\rreturn {}\rdef run_monitoring_cycle(self):\r\u0026quot;\u0026quot;\u0026quot;Execute complete monitoring cycle\u0026quot;\u0026quot;\u0026quot;\rprint(f\u0026quot;\\n=== EMR Monitoring Cycle - {datetime.utcnow().isoformat()} ===\u0026quot;)\rtry:\r# 1. Publish custom metrics\rprint(\u0026quot;1. Publishing custom metrics...\u0026quot;)\rself.publish_custom_metrics()\r# 2. Check cluster health\rprint(\u0026quot;2. Checking cluster health...\u0026quot;)\rhealth_report, issues = self.check_cluster_health()\rprint(f\u0026quot; Cluster State: {health_report.get('cluster_state', 'Unknown')}\u0026quot;)\rprint(f\u0026quot; Memory Available: {health_report.get('memory_available', 0):.1f}%\u0026quot;)\rprint(f\u0026quot; Hourly Cost: ${health_report.get('hourly_cost', 0):.3f}\u0026quot;)\rprint(f\u0026quot; Budget Used: {health_report.get('budget_utilization', 0):.1f}%\u0026quot;)\rif issues:\rprint(f\u0026quot; Issues Found: {len(issues)}\u0026quot;)\rfor issue in issues:\rprint(f\u0026quot; - {issue}\u0026quot;)\relse:\rprint(\u0026quot; Status: Healthy\u0026quot;)\r# 3. Automated remediation if needed\rif issues:\rprint(\u0026quot;3. Attempting automated remediation...\u0026quot;)\ractions = self.automated_remediation()\rif actions:\rfor action in actions:\rprint(f\u0026quot; - {action}\u0026quot;)\relse:\rprint(\u0026quot; - No automated actions available\u0026quot;)\r# 4. Generate cost report\rprint(\u0026quot;4. Generating cost report...\u0026quot;)\rcost_report = self.generate_cost_report()\rif cost_report.get('cost_optimization_tips'):\rprint(\u0026quot; Cost Optimization Tips:\u0026quot;)\rfor tip in cost_report['cost_optimization_tips']:\rprint(f\u0026quot; - {tip}\u0026quot;)\rprint(\u0026quot;=== Monitoring Cycle Complete ===\\n\u0026quot;)\rreturn {\r'success': True,\r'health_report': health_report,\r'issues': issues,\r'cost_report': cost_report\r}\rexcept Exception as e:\rprint(f\u0026quot;Error in monitoring cycle: {e}\u0026quot;)\rreturn {'success': False, 'error': str(e)}\rdef setup_complete_monitoring(self):\r\u0026quot;\u0026quot;\u0026quot;One-time setup for complete monitoring system\u0026quot;\u0026quot;\u0026quot;\rprint(\u0026quot;Setting up complete EMR monitoring system...\u0026quot;)\r# 1. Create SNS topics\rprint(\u0026quot;1. Creating SNS topics...\u0026quot;)\rself.setup_sns_topics()\r# 2. Create CloudWatch alarms\rprint(\u0026quot;2. Creating CloudWatch alarms...\u0026quot;)\rself.create_cloudwatch_alarms()\r# 3. Create dashboard\rprint(\u0026quot;3. Creating CloudWatch dashboard...\u0026quot;)\rself.create_dashboard()\r# 4. Initial metrics publication\rprint(\u0026quot;4. Publishing initial metrics...\u0026quot;)\rself.publish_custom_metrics()\rprint(\u0026quot;Complete monitoring system setup finished!\u0026quot;)\rprint(f\u0026quot;Dashboard URL: https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#dashboards:name=EMR-{self.cluster_id}-Monitoring\u0026quot;)\rUsage Examples and Main Execution if name == \u0026ldquo;main\u0026rdquo;: # Initialize monitoring system cluster_id = \u0026ldquo;j-xxxxx\u0026rdquo; # Replace with your cluster ID daily_budget = 100 # Set your daily budget\nmonitor = EMRMonitoringSystem(cluster_id, daily_budget)\r# One-time setup (run this once)\rprint(\u0026quot;=== SETUP PHASE ===\u0026quot;)\rmonitor.setup_complete_monitoring()\r# Continuous monitoring (run this regularly)\rprint(\u0026quot;\\n=== MONITORING PHASE ===\u0026quot;)\r# Run monitoring cycles\rfor cycle in range(3): # Run 3 cycles as example\rresult = monitor.run_monitoring_cycle()\rif not result['success']:\rprint(f\u0026quot;Monitoring cycle failed: {result.get('error')}\u0026quot;)\rbreak\r# Wait between cycles (in production, use cron/Lambda)\rprint(\u0026quot;Waiting 5 minutes before next cycle...\u0026quot;)\rtime.sleep(300) # 5 minutes\rprint(\u0026quot;Monitoring demonstration complete!\u0026quot;)\rAdditional utility functions for advanced monitoring class EMRAdvancedMonitoring: def init(self, cluster_id): self.cluster_id = cluster_id self.logs = boto3.client(\u0026rsquo;logs\u0026rsquo;) self.emr = boto3.client(\u0026rsquo;emr\u0026rsquo;)\ndef analyze_application_logs(self):\r\u0026quot;\u0026quot;\u0026quot;Analyze Spark application logs for performance insights\u0026quot;\u0026quot;\u0026quot;\rtry:\rlog_group = f'/aws/emr/{self.cluster_id}/step'\r# Query for common performance issues\rqueries = {\r'memory_errors': 'fields @timestamp, @message | filter @message like /OutOfMemoryError/ | sort @timestamp desc',\r'slow_tasks': 'fields @timestamp, @message | filter @message like /Task.*took.*ms/ | sort @timestamp desc',\r'failed_stages': 'fields @timestamp, @message | filter @message like /Stage.*failed/ | sort @timestamp desc'\r}\rinsights = {}\rfor query_name, query in queries.items():\rtry:\rresponse = self.logs.start_query(\rlogGroupName=log_group,\rstartTime=int((datetime.now() - timedelta(hours=1)).timestamp()),\rendTime=int(datetime.now().timestamp()),\rqueryString=query\r)\rquery_id = response['queryId']\r# Wait for query completion\rtime.sleep(5)\rresults = self.logs.get_query_results(queryId=query_id)\rinsights[query_name] = len(results.get('results', []))\rexcept Exception as e:\rinsights[query_name] = f\u0026quot;Error: {e}\u0026quot;\rreturn insights\rexcept Exception as e:\rreturn {'error': f\u0026quot;Log analysis failed: {e}\u0026quot;}\rdef get_spark_metrics(self):\r\u0026quot;\u0026quot;\u0026quot;Extract Spark-specific performance metrics\u0026quot;\u0026quot;\u0026quot;\rtry:\r# Get running steps\rsteps = self.emr.list_steps(\rClusterId=self.cluster_id,\rStepStates=['RUNNING', 'COMPLETED']\r)\rspark_metrics = {\r'total_steps': len(steps['Steps']),\r'running_steps': len([s for s in steps['Steps'] if s['Status']['State'] == 'RUNNING']),\r'completed_steps': len([s for s in steps['Steps'] if s['Status']['State'] == 'COMPLETED']),\r'failed_steps': len([s for s in steps['Steps'] if s['Status']['State'] == 'FAILED'])\r}\rreturn spark_metrics\rexcept Exception as e:\rreturn {'error': f\u0026quot;Spark metrics failed: {e}\u0026quot;}\rProduction deployment script def deploy_monitoring_lambda(): \u0026ldquo;\u0026ldquo;\u0026ldquo;Deploy monitoring as Lambda function for production\u0026rdquo;\u0026rdquo;\u0026rdquo; lambda_code = \u0026rsquo;\u0026rsquo;\u0026rsquo; import json import boto3 from datetime import datetime\ndef lambda_handler(event, context): cluster_id = event.get(\u0026lsquo;cluster_id\u0026rsquo;, \u0026lsquo;j-xxxxx\u0026rsquo;) daily_budget = event.get(\u0026lsquo;daily_budget\u0026rsquo;, 100)\nmonitor = EMRMonitoringSystem(cluster_id, daily_budget)\rresult = monitor.run_monitoring_cycle()\rreturn {\r'statusCode': 200,\r'body': json.dumps(result)\r}\r\u0026rsquo;\u0026rsquo;\u0026rsquo;\nprint(\u0026quot;Lambda deployment code generated.\u0026quot;)\rprint(\u0026quot;Deploy this as a Lambda function and schedule with EventBridge every 5 minutes.\u0026quot;)\rreturn lambda_code\rSlack integration for alerts def setup_slack_integration(): \u0026ldquo;\u0026ldquo;\u0026ldquo;Setup Slack webhook for alerts\u0026rdquo;\u0026rdquo;\u0026rdquo; slack_webhook_code = \u0026rsquo;\u0026rsquo;\u0026rsquo; import json import urllib3\ndef send_slack_alert(webhook_url, cluster_id, severity, message, details): http = urllib3.PoolManager()\ncolor_map = {\r'critical': '#FF0000',\r'warning': '#FFA500', 'info': '#00FF00',\r'cost': '#0000FF'\r}\rslack_message = {\r\u0026quot;attachments\u0026quot;: [\r{\r\u0026quot;color\u0026quot;: color_map.get(severity, '#808080'),\r\u0026quot;title\u0026quot;: f\u0026quot;EMR Alert - {cluster_id}\u0026quot;,\r\u0026quot;text\u0026quot;: message,\r\u0026quot;fields\u0026quot;: [\r{\u0026quot;title\u0026quot;: \u0026quot;Severity\u0026quot;, \u0026quot;value\u0026quot;: severity.upper(), \u0026quot;short\u0026quot;: True},\r{\u0026quot;title\u0026quot;: \u0026quot;Cluster\u0026quot;, \u0026quot;value\u0026quot;: cluster_id, \u0026quot;short\u0026quot;: True},\r{\u0026quot;title\u0026quot;: \u0026quot;Time\u0026quot;, \u0026quot;value\u0026quot;: datetime.utcnow().isoformat(), \u0026quot;short\u0026quot;: True}\r]\r}\r]\r}\rresponse = http.request(\r'POST',\rwebhook_url,\rbody=json.dumps(slack_message),\rheaders={'Content-Type': 'application/json'}\r)\rreturn response.status == 200\r\u0026rsquo;\u0026rsquo;\u0026rsquo;\nreturn slack_webhook_code\r``\nProduction Deployment Guide 1. Lambda Function Setup # Create Lambda function for monitoring aws lambda create-function \\ --function-name emr-monitoring \\ --runtime python3.9 \\ --role arn:aws:iam::123456789012:role/lambda-emr-role \\ --handler lambda_function.lambda_handler \\ --zip-file fileb://monitoring.zip 2. EventBridge Schedule Schedule monitoring every 5 minutes aws events put-rule \\ --name emr-monitoring-schedule \\ --schedule-expression \u0026#34;rate(5 minutes)\u0026#34; aws events put-targets \\ --rule emr-monitoring-schedule \\ --targets \u0026#34;Id\u0026#34;=\u0026#34;1\u0026#34;,\u0026#34;Arn\u0026#34;=\u0026#34;arn:aws:lambda:us-east-1:123456789012:function:emr-monitoring\u0026#34; 3. IAM Permissions Required { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;emr:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;sns:*\u0026#34;, \u0026#34;logs:*\u0026#34;, \u0026#34;ce:GetCostAndUsage\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Monitoring Checklist Pre-Production SNS topics created and subscribed CloudWatch alarms configured Dashboard created and accessible Lambda function deployed EventBridge schedule active IAM permissions verified Daily Operations Check dashboard for anomalies Review cost reports Validate alert notifications Monitor budget utilization Review performance trends Weekly Reviews Analyze cost optimization opportunities Review scaling patterns Update budget thresholds Check alarm effectiveness Performance trend analysis Conclusion What You\u0026rsquo;ve Accomplished: ‚úÖ Complete Monitoring: Real-time cluster and cost monitoring ‚úÖ Proactive Alerting: Multi-level alerts for different scenarios ‚úÖ Automated Remediation: Self-healing capabilities for common issues ‚úÖ Cost Tracking: Detailed cost analysis and budget management ‚úÖ Production Ready: Lambda deployment and scheduling Final Cost Savings Summary: Part 1 (Spot Instances): 39% savings Part 2 (Auto Scaling): 40% additional savings Part 3 (Monitoring): 15% additional savings through optimization Total Combined Savings: ~70% cost reduction Real-World Impact: Small company: $2,000/month ‚Üí $600/month = $1,400 saved Medium company: $10,000/month ‚Üí $3,000/month = $7,000 saved Large enterprise: $40,000/month ‚Üí $12,000/month = $28,000 saved Key Success Metrics: Cost Reduction: 70% average savings achieved Reliability: 99.9% uptime with automated remediation Performance: Maintained or improved job completion times Operational Efficiency: 80% reduction in manual intervention Pro Tip: The monitoring system pays for itself by preventing just one major cost overrun or performance issue!\rCongratulations! You\u0026rsquo;ve completed the comprehensive EMR Cost Optimization Workshop. Your clusters are now running at maximum efficiency with minimal cost and full observability.\nNext Steps: Apply these patterns to your production workloads and enjoy the significant cost savings!\n"
},
{
	"uri": "https://banh251o.github.io/EMR-Cost-Optimization-Workshop/4-workload-scheduling/",
	"title": "Part 4: Resource Cleanup",
	"tags": [],
	"description": "",
	"content": "Part 4: Clean Up Resources - Cost Management After completing the workshop, it\u0026rsquo;s crucial to clean up all resources to avoid unexpected charges. This section provides comprehensive cleanup procedures for all resources created during the workshop.\nüéØ Cleanup Objectives Terminate EMR clusters and associated resources Delete CloudWatch alarms, dashboards, and custom metrics Remove SNS topics and subscriptions Clean up Lambda functions and EventBridge rules Delete S3 buckets and logs (if created) Verify complete cleanup to avoid charges ‚ö†Ô∏è Important Warnings CRITICAL: Deleting resources is irreversible. Ensure you have backed up any important data before proceeding.\nCost Impact: Leaving resources running can result in significant charges. A single EMR cluster can cost $50-200+ per day.\nüßπ Complete Cleanup Guide Step 1: EMR Cluster Cleanup 1.1 List All EMR Clusters # List all clusters in your account aws emr list-clusters --active # List clusters by state aws emr list-clusters --cluster-states RUNNING WAITING STARTING 1.2 Terminate EMR Clusters # Terminate specific cluster aws emr terminate-clusters --cluster-ids j-xxxxx # Terminate multiple clusters aws emr terminate-clusters --cluster-ids j-xxxxx j-yyyyy j-zzzzz # Force terminate if needed aws emr terminate-clusters --cluster-ids j-xxxxx --force 1.3 Verify Cluster Termination # Check cluster status aws emr describe-cluster --cluster-id j-xxxxx --query \u0026#39;Cluster.Status.State\u0026#39; # Wait for termination aws emr wait cluster-terminated --cluster-id j-xxxxx Step 2: CloudWatch Resources Cleanup 2.1 Delete CloudWatch Alarms # List all EMR-related alarms aws cloudwatch describe-alarms --alarm-name-prefix \u0026#34;EMR-\u0026#34; # Delete specific alarms aws cloudwatch delete-alarms --alarm-names \\ \u0026#34;EMR-j-xxxxx-CriticalMemoryUsage\u0026#34; \\ \u0026#34;EMR-j-xxxxx-JobFailures\u0026#34; \\ \u0026#34;EMR-j-xxxxx-ClusterDown\u0026#34; \\ \u0026#34;EMR-j-xxxxx-HourlyCostHigh\u0026#34; \\ \u0026#34;EMR-j-xxxxx-BudgetExceeded\u0026#34; # Delete all EMR alarms (be careful!) aws cloudwatch describe-alarms --alarm-name-prefix \u0026#34;EMR-\u0026#34; \\ --query \u0026#39;MetricAlarms[].AlarmName\u0026#39; --output text | \\ xargs aws cloudwatch delete-alarms --alarm-names 2.2 Delete CloudWatch Dashboards # List dashboards aws cloudwatch list-dashboards --dashboard-name-prefix \u0026#34;EMR-\u0026#34; # Delete specific dashboard aws cloudwatch delete-dashboards --dashboard-names \u0026#34;EMR-j-xxxxx-Monitoring\u0026#34; # Delete all EMR dashboards aws cloudwatch list-dashboards --dashboard-name-prefix \u0026#34;EMR-\u0026#34; \\ --query \u0026#39;DashboardEntries[].DashboardName\u0026#39; --output text | \\ xargs aws cloudwatch delete-dashboards --dashboard-names 2.3 Clean Up Custom Metrics (Optional) # Note: Custom metrics automatically expire after 15 months # No direct delete command, but they stop incurring charges when not updated # List custom metrics aws cloudwatch list-metrics --namespace \u0026#34;EMR/CostOptimization\u0026#34; Step 3: SNS Topics Cleanup 3.1 List and Delete SNS Topics List all SNS topics aws sns list-topics\nDelete specific topics aws sns delete-topic --topic-arn arn:aws:sns:us-east-1:123456789012:emr-critical-alerts aws sns delete-topic --topic-arn arn:aws:sns:us-east-1:123456789012:emr-warning-alerts aws sns delete-topic --topic-arn arn:aws:sns:us-east-1:123456789012:emr-info-alerts aws sns delete-topic --topic-arn arn:aws:sns:us-east-1:123456789012:emr-cost-alerts 3.2 Unsubcribe from Topics # List subscriptions aws sns list-subscriptions # Unsubscribe aws sns unsubscribe --subscription-arn arn:aws:sns:us-east-1:123456789012:emr-alerts:xxxxx Step 4: Lambda Functions Cleanup 4.1 Delete Lambda Functions # List Lambda functions aws lambda list-functions --query \u0026#39;Functions[?contains(FunctionName, `emr`)].FunctionName\u0026#39; # Delete specific function aws lambda delete-function --function-name emr-monitoring # Delete function with all versions aws lambda delete-function --function-name emr-monitoring --qualifier \u0026#39;$LATEST\u0026#39; 4.2 Delete EventBridge Rules # List rules aws events list-rules --name-prefix \u0026#34;emr-\u0026#34; # Remove targets first aws events remove-targets --rule emr-monitoring-schedule --ids \u0026#34;1\u0026#34; # Delete rule aws events delete-rule --name emr-monitoring-schedule Step 5: S3 Resources Cleanup 5.1 Clean Up EMR Logs and Data # List S3 buckets used by EMR aws s3 ls | grep emr # Delete EMR log files (be careful!) aws s3 rm s3://your-emr-logs-bucket/ --recursive # Delete entire bucket (if safe to do so) aws s3 rb s3://your-emr-logs-bucket --force 5.2 Clean Up Bootstrap Scripts # Remove bootstrap scripts aws s3 rm s3://your-bucket/bootstrap/ --recursive Step 6: IAM Resources Cleanup (Optional) 6.1 Delete Custom IAM Roles (if created) # List EMR-related roles aws iam list-roles --query \u0026#39;Roles[?contains(RoleName, `EMR`)].RoleName\u0026#39; # Detach policies first aws iam detach-role-policy --role-name EMR-Custom-Role --policy-arn arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceRole # Delete role aws iam delete-role --role-name EMR-Custom-Role Step 7: EC2 Resources Cleanup 7.1 Clean Up Security Groups (if custom created) # List EMR security groups aws ec2 describe-security-groups --filters \u0026#34;Name=group-name,Values=*EMR*\u0026#34; # Delete custom security group (after cluster termination) aws ec2 delete-security-group --group-id sg-xxxxx 7.2 Clean Up Key Pairs (if created) # List key pairs aws ec2 describe-key-pairs # Delete key pair aws ec2 delete-key-pair --key-name emr-workshop-key "
},
{
	"uri": "https://banh251o.github.io/EMR-Cost-Optimization-Workshop/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://banh251o.github.io/EMR-Cost-Optimization-Workshop/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]