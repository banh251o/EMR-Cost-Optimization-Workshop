[
{
	"uri": "http://localhost:1313/000058-SessionManager/vi/",
	"title": "Workshop Tối ưu hóa Chi phí EMR",
	"tags": [],
	"description": "",
	"content": "Workshop Tối ưu hóa Chi phí EMR Tiết kiệm đến 70% chi phí Amazon EMR Chào mừng đến với Workshop tối ưu hóa chi phí Amazon EMR toàn diện! Học các chiến lược đã được chứng minh để giảm đáng kể chi phí EMR trong khi vẫn duy trì hiệu suất và độ tin cậy.\n🎯 Mục tiêu Workshop Sau khi hoàn thành workshop này, bạn sẽ:\nGiảm chi phí EMR 60-70% bằng spot instances và auto scaling Triển khai giám sát chủ động với cảnh báo và khắc phục tự động Thành thạo các kỹ thuật tối ưu chi phí production-ready Triển khai giám sát và quản trị cấp doanh nghiệp 💰 Tiết kiệm Chi phí Dự kiến Quy mô Công ty Trước Sau Tiết kiệm/Tháng Nhỏ $2,000 $600 $1,400 Trung bình $10,000 $3,000 $7,000 Lớn $40,000 $12,000 $28,000 📚 Cấu trúc Workshop Phần 1: Spot Instances (Tiết kiệm 39%) Mixed instance groups Xử lý interruption Best practices Phần 2: Auto Scaling (Tiết kiệm thêm 40%) Managed scaling policies Custom metrics Tối ưu hiệu suất Phần 3: Giám sát \u0026amp; Cảnh báo (Tiết kiệm thêm 15%) Theo dõi chi phí thời gian thực Khắc phục tự động Dashboard production Phần 4: Dọn dẹp Tài nguyên Quy trình dọn dẹp hoàn chỉnh Xác minh chi phí Best practices 🎓 Đối tượng Mục tiêu Chính:\nData Engineers (2+ năm kinh nghiệm) DevOps Engineers (có kiến thức AWS) Solutions Architects (tập trung tối ưu chi phí) Phụ:\nSenior Developers (kinh nghiệm big data) Cloud Engineers (kinh nghiệm EMR) Technical Leads (quản lý chi phí) ⏱️ Thời gian Tổng thời gian: 4-6 giờ\nPhần 1: 1.5 giờ Phần 2: 2 giờ Phần 3: 2.5 giờ Phần 4: 30 phút 📋 Yêu cầu Tiên quyết Kiến thức Bắt buộc ✅ AWS cơ bản (EC2, S3, IAM) ✅ EMR/Spark căn bản ✅ Kinh nghiệm command line ✅ Kiến thức Python cơ bản Quyền truy cập Bắt buộc ✅ AWS account với quyền EMR ✅ AWS CLI đã cấu hình ✅ Ngân sách $50-100 cho hands-on labs Công cụ Khuyến nghị ✅ AWS CLI v2 ✅ Python 3.7+ ✅ Text editor/IDE ✅ Web browser 🚀 Bắt đầu Thiết lập Yêu cầu - Cấu hình môi trường Phần 1: Spot Instances - Triển khai tiết kiệm 39% Phần 2: Auto Scaling - Thêm 40% tiết kiệm Phần 3: Giám sát - Khả năng quan sát hoàn chỉnh Phần 4: Dọn dẹp - Dọn dẹp tài nguyên 🏆 Chỉ số Thành công Sau khi hoàn thành workshop:\nGiảm chi phí 70% đạt được 99.9% uptime được duy trì 80% ít can thiệp thủ công hơn Giám sát production-ready được triển khai 💡 Công nghệ Chính Amazon EMR - Managed Hadoop/Spark EC2 Spot Instances - Tiết kiệm đến 90% Auto Scaling - Quản lý capacity động CloudWatch - Giám sát và cảnh báo Lambda - Khắc phục tự động SNS - Thông báo cảnh báo 🎉 Những gì bạn sẽ Xây dựng Hệ thống tối ưu hóa chi phí EMR hoàn chỉnh, production-ready bao gồm:\nQuản lý spot instance thông minh Chính sách auto scaling động Giám sát chi phí thời gian thực Khắc phục tự động Dashboard điều hành Mẹo chuyên nghiệp: Workshop này tự hoàn vốn chỉ bằng việc ngăn chặn một lần vượt chi phí!\nSẵn sàng tiết kiệm hàng nghìn đô la cho chi phí EMR? Hãy bắt đầu!\n"
},
{
	"uri": "http://localhost:1313/000058-SessionManager/vi/1-spot-instances/",
	"title": "Phần 1: Spot Instances",
	"tags": [],
	"description": "",
	"content": "Phần 1: Sử dụng Spot Instances để giảm chi phí Trong phần này, bạn sẽ học cách tạo EMR cluster sử dụng Spot Instances để giảm chi phí từ 60-70% so với On-Demand instances.\nSpot Instances là gì? Spot Instances là các EC2 instances không sử dụng của AWS, được bán với giá thấp hơn nhiều so với On-Demand. Tuy nhiên, AWS có thể thu hồi chúng bất cứ lúc nào khi có nhu cầu.\nƯu điểm:\nGiá rẻ hơn 50-90% so với On-Demand Phù hợp cho workloads có thể chịu được interruption Tích hợp tốt với EMR Nhược điểm:\nCó thể bị terminate bất cứ lúc nào Không phù hợp cho workloads critical Cần thiết kế application để handle interruption Chiến lược sử dụng Spot với EMR 1. Mixed Instance Types Sử dụng nhiều loại instance khác nhau để tăng availability:\nm5.large, m4.large, c5.large Nếu một loại bị terminate, các loại khác vẫn chạy 2. Phân chia vai trò Master node: Luôn dùng On-Demand (quan trọng nhất) Core nodes: Một phần On-Demand, một phần Spot Task nodes: 100% Spot (có thể terminate mà không mất data) 3. Bidding Strategy Đặt bid price cao hơn current spot price 10-20% Theo dõi spot price history để đặt giá hợp lý Thực hành: Tạo EMR Cluster với Spot Bước 1: Chuẩn bị Trước khi tạo cluster, bạn cần:\nĐăng nhập AWS Console Chọn region (khuyến nghị: us-east-1) Tạo EC2 Key Pair nếu chưa có Kiểm tra IAM roles: EMR_DefaultRole và EMR_EC2_DefaultRole Bước 2: Tạo Cluster qua Console Mở AWS Console → EMR Click \u0026ldquo;Create cluster\u0026rdquo; Chọn \u0026ldquo;Go to advanced options\u0026rdquo; Cấu hình Software:\nRelease: emr-6.15.0 Applications: Spark, Hadoop Cấu hình Hardware:\nMaster: 1 x m5.xlarge (On-Demand) Core: 1 x m5.large (On-Demand) + 2 x m5.large (Spot, bid $0.05) Task: 4 x m5.large (Spot, bid $0.05) Cấu hình General:\nCluster name: \u0026ldquo;Workshop-Spot-Cluster\u0026rdquo; Logging: Enable (chọn S3 bucket) Termination protection: Disable Bước 3: Theo dõi Cluster Sau khi tạo cluster:\nTheo dõi trạng thái trong EMR Console Kiểm tra Hardware tab để xem instances Xem Spot price history trong EC2 Console Bước 4: So sánh Chi phí Cấu hình On-Demand:\nMaster: 1 x m5.xlarge = $0.192/giờ Workers: 6 x m5.large = $0.576/giờ Tổng: $0.768/giờ Cấu hình Spot:\nMaster: 1 x m5.xlarge = $0.192/giờ Core On-Demand: 1 x m5.large = $0.096/giờ Spot instances: 6 x m5.large = $0.180/giờ (giả sử spot price $0.03) Tổng: $0.468/giờ Tiết kiệm: 39% ($0.30/giờ)\nXử lý Spot Interruption Monitoring Interruptions EMR tự động xử lý spot interruptions:\nTask nodes bị terminate: Jobs được redistribute Core nodes bị terminate: Data được replicate Cluster tiếp tục chạy với instances còn lại Best Practices Checkpoint thường xuyên: Lưu intermediate results Sử dụng S3: Store data ngoài cluster Mixed instance types: Giảm risk tất cả bị terminate cùng lúc Monitor spot prices: Adjust bid prices khi cần Lab Exercise: Test Spot Interruption Tạo Test Job SSH vào master node Tạo file test job: # simple-job.py from pyspark.sql import SparkSession import time spark = SparkSession.builder.appName(\u0026#34;SpotTest\u0026#34;).getOrCreate() # Tạo large dataset df = spark.range(0, 10000000).toDF(\u0026#34;id\u0026#34;) df = df.repartition(100) # Chạy job lâu để test interruption for i in range(10): result = df.count() print(f\u0026#34;Iteration {i}: Count = {result}\u0026#34;) time.sleep(60) # Chờ 1 phút spark.stop() Submit job: spark-submit simple-job.py Simulate Interruption Trong EC2 Console, terminate một spot instance Quan sát job vẫn tiếp tục chạy Kiểm tra EMR Console xem cluster status Kết quả Phần 1 Sau khi hoàn thành phần này, bạn đã: ✅ Hiểu cách Spot Instances hoạt động với EMR ✅ Tạo được cluster với mixed instance types ✅ Tiết kiệm 39% chi phí so với On-Demand ✅ Test được spot interruption handling Chi phí thực tế: Cluster chạy 1 giờ = ~$0.47 (thay vì $0.77) Chúc mừng! Bạn đã tạo thành công EMR cluster với Spot Instances và tiết kiệm được chi phí đáng kể. Tiếp theo, chúng ta sẽ học Auto Scaling để tối ưu hóa thêm.\rLưu ý: Đừng terminate cluster ngay! Chúng ta sẽ sử dụng cluster này cho Phần 2: Auto Scaling.\rCâu hỏi thường gặp Q: Spot instances có đáng tin cậy không? A: Với EMR, spot instances rất đáng tin cậy vì EMR tự động handle interruptions. Chỉ cần thiết kế job properly. **Q:Khi nào nên sử dụng Spot instances?** A: Spot instances phù hợp cho batch processing, data analysis, machine learning training - các workloads có thể restart được. **Q: Làm sao biết bid price phù hợp?** A: Kiểm tra Spot Price History trong EC2 Console, đặt bid cao hơn average price 10-20%. **Q: Nếu tất cả spot instances bị terminate thì sao?** A: EMR sẽ tự động launch instances mới. Job có thể restart từ checkpoint gần nhất. --- **Tiếp theo:** [Phần 2: Auto Scaling](/02-auto-scaling) để học cách tự động điều chỉnh cluster size theo workload. "
},
{
	"uri": "http://localhost:1313/000058-SessionManager/vi/2-auto-scaling/",
	"title": "Phần 2: Auto Scaling",
	"tags": [],
	"description": "",
	"content": "Phần 2: EMR Auto Scaling - Tự động điều chỉnh theo workload Trong phần này, bạn sẽ học cách thiết lập EMR Auto Scaling để cluster tự động tăng giảm số lượng instances theo workload, giúp tối ưu hóa cả chi phí và performance.\nEMR Auto Scaling là gì? EMR Auto Scaling tự động điều chỉnh số lượng instances trong cluster dựa trên:\nYARN metrics: Memory và CPU utilization Custom metrics: CloudWatch metrics tùy chỉnh Time-based scaling: Theo lịch trình định sẵn Lợi ích:\nTiết kiệm chi phí khi workload thấp Tăng performance khi workload cao Không cần can thiệp thủ công Tích hợp tốt với Spot Instances Các loại Auto Scaling 1. EMR Managed Scaling (Khuyến nghị) AWS quản lý hoàn toàn Dựa trên YARN container pending Đơn giản, hiệu quả Hỗ trợ cả On-Demand và Spot 2. Custom Auto Scaling Tự định nghĩa scaling policies Dựa trên CloudWatch metrics Linh hoạt hơn nhưng phức tạp Phù hợp cho use cases đặc biệt Thực hành: Thiết lập Managed Scaling Bước 1: Enable Managed Scaling Sử dụng cluster từ Phần 1, chúng ta sẽ enable auto scaling:\nMở EMR Console Chọn cluster \u0026ldquo;Workshop-Spot-Cluster\u0026rdquo; Vào tab \u0026ldquo;Configuration\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; ở phần \u0026ldquo;Scaling\u0026rdquo; Cấu hình Managed Scaling:\nMinimum capacity: 2 instances Maximum capacity: 10 instances Maximum On-Demand capacity: 4 instances Bước 2: Cấu hình Advanced Settings Scale-out settings:\nScale out cooldown: 300 seconds Maximum scale-out increment: 100% Scale-in settings:\nScale in cooldown: 300 seconds Maximum scale-in increment: 50% Bước 3: Kiểm tra Configuration Sau khi enable, kiểm tra:\nScaling status: \u0026ldquo;Enabled\u0026rdquo; Current capacity: 7 instances (từ Phần 1) Target capacity: Sẽ thay đổi theo workload Test Auto Scaling Tạo Workload để Test Scaling SSH vào Master Node: ssh -i your-key.pem hadoop@master-public-ip\nTạo Test Script: ``python\nscaling-test.py from pyspark.sql import SparkSession import time\nspark = SparkSession.builder .appName(\u0026ldquo;AutoScalingTest\u0026rdquo;) .config(\u0026ldquo;spark.sql.adaptive.enabled\u0026rdquo;, \u0026ldquo;false\u0026rdquo;) .config(\u0026ldquo;spark.sql.adaptive.coalescePartitions.enabled\u0026rdquo;, \u0026ldquo;false\u0026rdquo;) .getOrCreate()\nprint(\u0026quot;=== Starting Auto Scaling Test ===\u0026quot;)\nTạo large dataset để trigger scaling print(\u0026ldquo;Creating large dataset\u0026hellip;\u0026rdquo;) df = spark.range(0, 100000000).toDF(\u0026ldquo;id\u0026rdquo;) df = df.repartition(200) # Nhiều partitions để cần nhiều resources\nCache để consume memory df.cache()\nChạy multiple operations để maintain load for i in range(5): print(f\u0026quot;Running operation {i+1}/5\u0026hellip;\u0026quot;)\n# Heavy computation\rresult = df.filter(df.id % 2 == 0).count()\rprint(f\u0026quot;Even numbers count: {result}\u0026quot;)\r# Giữ load trong 5 phút để observe scaling\rtime.sleep(300)\rprint(\u0026quot;=== Test completed ===\u0026quot;) spark.stop() ``\nSubmit Job: spark-submit \\\r--executor-memory 2g \\\r--num-executors 15 \\\r--executor-cores 2 \\\rscaling-test.py Theo dõi Scaling Process Trong EMR Console:\nVào tab \u0026ldquo;Hardware\u0026rdquo; để xem instances Refresh mỗi 2-3 phút Quan sát số lượng instances tăng lên Trong CloudWatch:\nMở CloudWatch Console Vào \u0026ldquo;Metrics\u0026rdquo; → \u0026ldquo;AWS/ElasticMapReduce\u0026rdquo; Chọn metrics: YARNMemoryAvailablePercentage ContainerPending AppsRunning Expected Behavior:\nPhút 0-2: Job bắt đầu, YARN memory giảm Phút 2-5: ContainerPending tăng, scaling triggered Phút 5-8: Instances mới được add (2-3 instances) Phút 8-25: Job chạy với capacity mới Phút 25-30: Job kết thúc, scaling down bắt đầu Monitoring và Troubleshooting Key Metrics để Monitor YARN Metrics:\nYARNMemoryAvailablePercentage: \u0026lt; 15% trigger scale out ContainerPending: \u0026gt; 0 trong 5 phút trigger scale out AppsRunning: Số applications đang chạy EMR Metrics:\nRunningMapTasks: Map tasks đang chạy RunningReduceTasks: Reduce tasks đang chạy TotalLoad: Tổng load của cluster Common Issues và Solutions Issue 1: Scaling không hoạt động\nKiểm tra IAM permissions Verify scaling limits (min/max capacity) Check cooldown periods Issue 2: Scale out quá chậm\nGiảm scale-out cooldown Tăng maximum scale-out increment Sử dụng multiple instance types Issue 3: Scale in quá nhanh\nTăng scale-in cooldown Giảm maximum scale-in increment Adjust YARN memory thresholds Advanced Scaling Strategies 1. Mixed Instance Types cho Scaling Cấu hình multiple instance types để tăng availability:\nInstance Fleet Configuration:\nPrimary: m5.large (Spot) Secondary: m4.large (Spot) Fallback: c5.large (Spot) Emergency: m5.large (On-Demand) 2. Time-based Scaling Cho workloads có pattern cố định:\nScale out trước peak hours Scale in sau off-peak hours Sử dụng CloudWatch Events + Lambda 3. Predictive Scaling Dựa trên historical data:\nAnalyze past workload patterns Pre-scale cho expected load Combine với reactive scaling Cost Optimization với Auto Scaling Before Auto Scaling (Static Cluster) Peak capacity: 10 instances × 8 hours = 80 instance-hours Cost: 80 × $0.096 = $7.68/day After Auto Scaling (Dynamic Cluster) Average capacity: 4 instances × 8 hours = 32 instance-hours Peak capacity: 8 instances × 2 hours = 16 instance-hours Total: 32 + 16 = 48 instance-hours Cost: 48 × $0.096 = $4.61/day Tiết kiệm: $3.07/day (40% cost reduction)\nLab Exercise: Custom Scaling Policy Tạo Custom CloudWatch Alarm Tạo Scale-Out Alarm: aws cloudwatch put-metric-alarm \\\r--alarm-name \u0026quot;EMR-ScaleOut-HighMemory\u0026quot; \\\r--alarm-description \u0026quot;Scale out when memory usage \u0026gt; 80%\u0026quot; \\\r--metric-name YARNMemoryAvailablePercentage \\\r--namespace AWS/ElasticMapReduce \\\r--statistic Average \\\r--period 300 \\\r--threshold 20 \\\r--comparison-operator LessThanThreshold \\\r--evaluation-periods 2 \\\r--dimensions Name=JobFlowId,Value=j-xxxxx\nTạo Scale-In Alarm: aws cloudwatch put-metric-alarm \\\r--alarm-name \u0026quot;EMR-ScaleIn-LowMemory\u0026quot; \\\r--alarm-description \u0026quot;Scale in when memory usage \u0026lt; 30%\u0026quot; \\\r--metric-name YARNMemoryAvailablePercentage \\\r--namespace AWS/ElasticMapReduce \\\r--statistic Average \\\r--period 600 \\\r--threshold 70 \\\r--comparison-operator GreaterThanThreshold \\\r--evaluation-periods 3 \\\r--dimensions Name=JobFlowId,Value=j-xxxxx\nTest Custom Scaling Tạo Light Workload: ``python light-workload.py from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\u0026ldquo;LightWorkload\u0026rdquo;).getOrCreate()\nSmall dataset df = spark.range(0, 1000000).toDF(\u0026ldquo;id\u0026rdquo;) result = df.count() print(f\u0026quot;Light workload result: {result}\u0026quot;)\nspark.stop() ``\nSubmit và Monitor: spark-submit light-workload.py\nQuan sát Scale-In:\nMemory usage giảm xuống \u0026lt; 30% Sau 10 phút, cluster scale in Instances giảm từ 8 xuống 4 Production Best Practices 1. Scaling Configuration Recommended Settings:\nMin capacity: 20% của peak capacity Max capacity: 150% của expected peak Scale-out cooldown: 300 seconds Scale-in cooldown: 600 seconds 2. Instance Mix Strategy Optimal Mix:\n30% On-Demand (stability) 70% Spot (cost savings) Multiple instance families Diversified AZs 3. Application Design Scaling-Friendly Applications:\nStateless processing Checkpointing enabled Graceful handling của node loss Partition data appropriately 4. Monitoring Setup Essential Metrics:\nCluster utilization Scaling events Job completion times Cost per job Kết quả Phần 2 Sau khi hoàn thành phần này, bạn đã:\n✅ Thiết lập EMR Managed Scaling thành công ✅ Test scaling với real workload ✅ Hiểu cách monitor scaling metrics ✅ Tối ưu hóa thêm 40% chi phí với dynamic scaling Tổng tiết kiệm đến giờ:\nSpot Instances: 39% (từ Phần 1) Auto Scaling: 40% (từ Phần 2) Combined savings: ~65% so với static On-Demand cluster Xuất sắc! Cluster của bạn giờ đã tự động scale theo workload và tiết kiệm tối đa chi phí. Tiếp theo, chúng ta sẽ thiết lập monitoring để theo dõi mọi thứ.\nTroubleshooting Common Issues Issue: Scaling Events không xuất hiện Nguyên nhân có thể:\nIAM role thiếu permissions Cooldown period chưa hết Metrics chưa đạt threshold Giải pháp:\nKiểm tra CloudTrail logs Verify EMR service role permissions Adjust threshold values Issue: Scale-in quá aggressive Triệu chứng:\nInstances bị terminate khi job vẫn chạy Performance degradation Giải pháp:\nTăng scale-in cooldown lên 900s Giảm maximum scale-in increment xuống 25% Set higher memory threshold (80% thay vì 70%) Issue: Spot instances không được add khi scaling Nguyên nhân:\nSpot capacity không available Bid price quá thấp Instance type constraints Giải pháp:\nThêm multiple instance types Tăng bid price Enable multiple AZs Performance Tuning Tips 1. Optimize Spark Configuration # Spark configs cho auto-scaling environment\rspark.dynamicAllocation.enabled=true\rspark.dynamicAllocation.minExecutors=2\rspark.dynamicAllocation.maxExecutors=50\rspark.dynamicAllocation.initialExecutors=5\n2. YARN Configuration ``xml\n3. EMR Steps Optimization Sử dụng cluster mode thay vì client mode Enable speculation cho fault tolerance Configure appropriate parallelism Real-world Example: E-commerce Analytics Scenario Công ty e-commerce cần process log data hàng ngày:\nMorning (6-10 AM): Light processing (2-3 instances) Afternoon (2-6 PM): Heavy analytics (8-12 instances) Night (10 PM-2 AM): Batch reports (4-6 instances) Auto Scaling Configuration # Managed scaling policy\r{\r\u0026quot;ComputeLimits\u0026quot;: {\r\u0026quot;UnitType\u0026quot;: \u0026quot;Instances\u0026quot;,\r\u0026quot;MinimumCapacityUnits\u0026quot;: 2,\r\u0026quot;MaximumCapacityUnits\u0026quot;: 15,\r\u0026quot;MaximumOnDemandCapacityUnits\u0026quot;: 5,\r\u0026quot;MaximumCoreCapacityUnits\u0026quot;: 8\r}\r}\nCost Comparison Before Auto Scaling:\nStatic 12 instances × 24 hours = 288 instance-hours Cost: 288 × $0.096 = $27.65/day After Auto Scaling:\nAverage 5 instances × 24 hours = 120 instance-hours Cost: 120 × $0.096 = $11.52/day Savings: $16.13/day (58%) Advanced Monitoring Setup Custom Metrics Dashboard Tạo CloudWatch dashboard với:\nCluster capacity over time Cost per hour tracking Job completion rates Scaling events timeline Automated Alerts Setup alerts cho:\nScaling failures High cost thresholds Performance degradation Spot interruption rates Cost Tracking Script ``python\ncost-tracker.py import boto3 from datetime import datetime, timedelta\ndef track_emr_costs(cluster_id): emr = boto3.client(\u0026rsquo;emr\u0026rsquo;) ce = boto3.client(\u0026lsquo;ce\u0026rsquo;)\n# Get cluster info\rcluster = emr.describe_cluster(ClusterId=cluster_id)\rstart_time = cluster['Cluster']['Status']['Timeline']['CreationDateTime']\r# Calculate cost\rend_time = datetime.now()\rresponse = ce.get_cost_and_usage(\rTimePeriod={\r'Start': start_time.strftime('%Y-%m-%d'),\r'End': end_time.strftime('%Y-%m-%d')\r},\rGranularity='DAILY',\rMetrics=['BlendedCost'],\rGroupBy=[\r{'Type': 'DIMENSION', 'Key': 'SERVICE'}\r]\r)\rprint(f\u0026quot;Cluster {cluster_id} cost tracking:\u0026quot;)\rfor result in response['ResultsByTime']:\rfor group in result['Groups']:\rif 'ElasticMapReduce' in group['Keys'][0]:\rcost = group['Metrics']['BlendedCost']['Amount']\rprint(f\u0026quot;Date: {result['TimePeriod']['Start']}, Cost: ${cost}\u0026quot;)\rUsage track_emr_costs(\u0026lsquo;j-xxxxx\u0026rsquo;) ``\nScaling Patterns Analysis Pattern 1: Batch Processing Characteristics:\nPredictable workload times High resource usage during processing Idle periods between jobs Optimal Strategy:\nAggressive scale-out (200% increment) Conservative scale-in (25% increment) Longer cooldown periods (600s) Pattern 2: Interactive Analytics Characteristics:\nUnpredictable query patterns Variable resource requirements Need for quick response times Optimal Strategy:\nModerate scale-out (100% increment) Quick scale-in (50% increment) Shorter cooldown periods (300s) Pattern 3: Streaming Workloads Characteristics:\nContinuous data processing Steady resource usage Occasional spikes Optimal Strategy:\nConservative scaling (50% increment) Maintain minimum baseline Focus on stability over cost Integration với Other AWS Services 1. Lambda Triggers Tự động start/stop clusters: ``python\nlambda-emr-scheduler.py import boto3 import json\ndef lambda_handler(event, context): emr = boto3.client(\u0026rsquo;emr\u0026rsquo;)\nif event['action'] == 'start':\r# Start cluster with auto-scaling\rresponse = emr.run_job_flow(\rName='Scheduled-Cluster',\rReleaseLabel='emr-6.15.0',\rInstances={\r'MasterInstanceType': 'm5.xlarge',\r'SlaveInstanceType': 'm5.large',\r'InstanceCount': 3,\r'Ec2KeyName': 'your-key'\r},\rApplications=[{'Name': 'Spark'}],\rServiceRole='EMR_DefaultRole',\rJobFlowRole='EMR_EC2_DefaultRole'\r)\rcluster_id = response['JobFlowId']\r# Enable managed scaling\remr.put_managed_scaling_policy(\rClusterId=cluster_id,\rManagedScalingPolicy={\r'ComputeLimits': {\r'UnitType': 'Instances',\r'MinimumCapacityUnits': 2,\r'MaximumCapacityUnits': 10\r}\r}\r)\rreturn {'statusCode': 200, 'body': f'Started cluster: {cluster_id}'}\relif event['action'] == 'stop':\r# Terminate cluster\remr.terminate_job_flows(JobFlowIds=[event['cluster_id']])\rreturn {'statusCode': 200, 'body': 'Cluster terminated'}\r``\n2. Step Functions Orchestration Workflow cho complex data pipelines: json\r{\r\u0026quot;Comment\u0026quot;: \u0026quot;EMR Auto-scaling Pipeline\u0026quot;,\r\u0026quot;StartAt\u0026quot;: \u0026quot;CreateCluster\u0026quot;,\r\u0026quot;States\u0026quot;: {\r\u0026quot;CreateCluster\u0026quot;: {\r\u0026quot;Type\u0026quot;: \u0026quot;Task\u0026quot;,\r\u0026quot;Resource\u0026quot;: \u0026quot;arn:aws:states:::emr:createCluster.sync\u0026quot;,\r\u0026quot;Parameters\u0026quot;: {\r\u0026quot;Name\u0026quot;: \u0026quot;Pipeline-Cluster\u0026quot;,\r\u0026quot;ReleaseLabel\u0026quot;: \u0026quot;emr-6.15.0\u0026quot;\r},\r\u0026quot;Next\u0026quot;: \u0026quot;EnableScaling\u0026quot;\r},\r\u0026quot;EnableScaling\u0026quot;: {\r\u0026quot;Type\u0026quot;: \u0026quot;Task\u0026quot;,\r\u0026quot;Resource\u0026quot;: \u0026quot;arn:aws:states:::aws-sdk:emr:putManagedScalingPolicy\u0026quot;,\r\u0026quot;Parameters\u0026quot;: {\r\u0026quot;ClusterId.$\u0026quot;: \u0026quot;$.ClusterId\u0026quot;,\r\u0026quot;ManagedScalingPolicy\u0026quot;: {\r\u0026quot;ComputeLimits\u0026quot;: {\r\u0026quot;UnitType\u0026quot;: \u0026quot;Instances\u0026quot;,\r\u0026quot;MinimumCapacityUnits\u0026quot;: 2,\r\u0026quot;MaximumCapacityUnits\u0026quot;: 20\r}\r}\r},\r\u0026quot;Next\u0026quot;: \u0026quot;ProcessData\u0026quot;\r},\r\u0026quot;ProcessData\u0026quot;: {\r\u0026quot;Type\u0026quot;: \u0026quot;Task\u0026quot;,\r\u0026quot;Resource\u0026quot;: \u0026quot;arn:aws:states:::emr:addStep.sync\u0026quot;,\r\u0026quot;End\u0026quot;: true\r}\r}\r}\r3. EventBridge Rules Tự động respond to scaling events: json\r{\r\u0026quot;Rules\u0026quot;: [\r{\r\u0026quot;Name\u0026quot;: \u0026quot;EMR-ScaleOut-Alert\u0026quot;,\r\u0026quot;EventPattern\u0026quot;: {\r\u0026quot;source\u0026quot;: [\u0026quot;aws.emr\u0026quot;],\r\u0026quot;detail-type\u0026quot;: [\u0026quot;EMR Instance Group State Change\u0026quot;],\r\u0026quot;detail\u0026quot;: {\r\u0026quot;state\u0026quot;: [\u0026quot;RUNNING\u0026quot;],\r\u0026quot;requestedInstanceCount\u0026quot;: {\r\u0026quot;numeric\u0026quot;: [\u0026quot;\u0026gt;\u0026quot;, 5]\r}\r}\r},\r\u0026quot;Targets\u0026quot;: [\r{\r\u0026quot;Id\u0026quot;: \u0026quot;1\u0026quot;,\r\u0026quot;Arn\u0026quot;: \u0026quot;arn:aws:sns:us-east-1:123456789012:emr-alerts\u0026quot;\r}\r]\r}\r]\r}\rFinal Lab: End-to-End Scenario Scenario Setup Tạo một complete data processing pipeline:\nData Ingestion: S3 → EMR Processing: Spark jobs với auto-scaling Output: Results → S3 Monitoring: CloudWatch dashboard Cleanup: Automatic termination Implementation Steps Upload Sample Data: aws s3 cp sample-data.csv s3://your-bucket/input/\nCreate Processing Script: ``python\nend-to-end-pipeline.py from pyspark.sql import SparkSession from pyspark.sql.functions import *\nspark = SparkSession.builder.appName(\u0026ldquo;E2EPipeline\u0026rdquo;).getOrCreate()\nRead data from S3 df = spark.read.csv(\u0026ldquo;s3://your-bucket/input/sample-data.csv\u0026rdquo;, header=True)\nHeavy processing to trigger scaling df_processed = df.groupBy(\u0026ldquo;category\u0026rdquo;).agg( count(\u0026quot;*\u0026quot;).alias(\u0026ldquo;count\u0026rdquo;), avg(\u0026ldquo;value\u0026rdquo;).alias(\u0026ldquo;avg_value\u0026rdquo;), max(\u0026ldquo;value\u0026rdquo;).alias(\u0026ldquo;max_value\u0026rdquo;) ).repartition(50) # Force many partitions\nCache to consume memory df_processed.cache()\nMultiple operations result1 = df_processed.filter(col(\u0026ldquo;count\u0026rdquo;) \u0026gt; 100).count() result2 = df_processed.orderBy(desc(\u0026ldquo;avg_value\u0026rdquo;)).collect()\nWrite results df_processed.write.mode(\u0026ldquo;overwrite\u0026rdquo;).csv(\u0026ldquo;s3://your-bucket/output/\u0026rdquo;)\nprint(f\u0026quot;Pipeline completed. Processed {result1} categories\u0026quot;) spark.stop() ``\nSubmit Pipeline: aws emr add-steps --cluster-id j-xxxxx \\\r--steps '[{\r\u0026quot;Name\u0026quot;: \u0026quot;E2E-Pipeline\u0026quot;,\r\u0026quot;ActionOnFailure\u0026quot;: \u0026quot;TERMINATE_CLUSTER\u0026quot;,\r\u0026quot;HadoopJarStep\u0026quot;: {\r\u0026quot;Jar\u0026quot;: \u0026quot;command-runner.jar\u0026quot;,\r\u0026quot;Args\u0026quot;: [\r\u0026quot;spark-submit\u0026quot;,\r\u0026quot;--executor-memory\u0026quot;, \u0026quot;2g\u0026quot;,\r\u0026quot;--num-executors\u0026quot;, \u0026quot;20\u0026quot;,\r\u0026quot;s3://your-bucket/scripts/end-to-end-pipeline.py\u0026quot;\r]\r}\r}]'\nMonitor Complete Workflow:\nCluster starts với 3 instances Job bắt đầu, memory usage tăng Auto-scaling kicks in, thêm 4-6 instances Processing completes Scale-in begins, giảm về 3 instances Job finishes, cluster có thể terminate Expected Timeline 0-5 min: Job startup, initial processing 5-10 min: Heavy load, scaling out to 8-10 instances 10-25 min: Processing với full capacity 25-30 min: Job completion, scaling in 30-35 min: Final cleanup, cluster ready for next job Performance Metrics Analysis Key Performance Indicators (KPIs) Cost Efficiency:\nCost per GB processed Cost per job completion Utilization percentage Performance:\nJob completion time Throughput (GB/hour) Resource efficiency Reliability:\nSuccess rate Spot interruption impact Recovery time Benchmarking Results Static Cluster (Baseline):\n10 instances × 2 hours = 20 instance-hours Cost: $1.92 Processing time: 45 minutes Utilization: 60% Auto-Scaling Cluster:\nAverage 6 instances × 2 hours = 12 instance-hours Cost: $1.15 Processing time: 50 minutes Utilization: 85% Improvement:\n40% cost reduction 25% better utilization Only 11% longer processing time Graduation Exercise Challenge: Optimize Real Workload Bạn được cung cấp một dataset 10GB và yêu cầu:\nProcess data với budget tối đa $2 Complete trong 60 phút Achieve 80%+ cluster utilization Handle ít nhất 1 spot interruption Solution Approach Cluster Configuration: json\r{\r\u0026quot;InstanceGroups\u0026quot;: [\r{\r\u0026quot;Name\u0026quot;: \u0026quot;Master\u0026quot;,\r\u0026quot;InstanceRole\u0026quot;: \u0026quot;MASTER\u0026quot;, \u0026quot;InstanceType\u0026quot;: \u0026quot;m5.large\u0026quot;,\r\u0026quot;InstanceCount\u0026quot;: 1,\r\u0026quot;Market\u0026quot;: \u0026quot;ON_DEMAND\u0026quot;\r},\r{\r\u0026quot;Name\u0026quot;: \u0026quot;Core\u0026quot;,\r\u0026quot;InstanceRole\u0026quot;: \u0026quot;CORE\u0026quot;,\r\u0026quot;InstanceType\u0026quot;: \u0026quot;m5.large\u0026quot;, \u0026quot;InstanceCount\u0026quot;: 1,\r\u0026quot;Market\u0026quot;: \u0026quot;ON_DEMAND\u0026quot;\r},\r{\r\u0026quot;Name\u0026quot;: \u0026quot;Task\u0026quot;,\r\u0026quot;InstanceRole\u0026quot;: \u0026quot;TASK\u0026quot;,\r\u0026quot;InstanceType\u0026quot;: \u0026quot;m5.large\u0026quot;,\r\u0026quot;InstanceCount\u0026quot;: 0,\r\u0026quot;Market\u0026quot;: \u0026quot;SPOT\u0026quot;,\r\u0026quot;BidPrice\u0026quot;: \u0026quot;0.04\u0026quot;\r}\r]\r}\rScaling Policy: json\r{\r\u0026quot;ComputeLimits\u0026quot;: {\r\u0026quot;UnitType\u0026quot;: \u0026quot;Instances\u0026quot;,\r\u0026quot;MinimumCapacityUnits\u0026quot;: 2,\r\u0026quot;MaximumCapacityUnits\u0026quot;: 12,\r\u0026quot;MaximumOnDemandCapacityUnits\u0026quot;: 2,\r\u0026quot;MaximumCoreCapacityUnits\u0026quot;: 2\r}\r}\rOptimized Spark Job: ``python\noptimized-processing.py from pyspark.sql import SparkSession from pyspark.sql.functions import *\nspark = SparkSession.builder .appName(\u0026ldquo;OptimizedProcessing\u0026rdquo;) .config(\u0026ldquo;spark.sql.adaptive.enabled\u0026rdquo;, \u0026ldquo;true\u0026rdquo;) .config(\u0026ldquo;spark.sql.adaptive.coalescePartitions.enabled\u0026rdquo;, \u0026ldquo;true\u0026rdquo;) .config(\u0026ldquo;spark.serializer\u0026rdquo;, \u0026ldquo;org.apache.spark.serializer.KryoSerializer\u0026rdquo;) .getOrCreate()\nEfficient data reading df = spark.read.parquet(\u0026ldquo;s3://your-bucket/data/\u0026rdquo;) .repartition(100) # Optimal partitioning\nCheckpoint để handle spot interruptions spark.sparkContext.setCheckpointDir(\u0026ldquo;s3://your-bucket/checkpoints/\u0026rdquo;) df.checkpoint()\nProcessing với caching strategy df_processed = df.groupBy(\u0026ldquo;category\u0026rdquo;, \u0026ldquo;date\u0026rdquo;) .agg( sum(\u0026ldquo;amount\u0026rdquo;).alias(\u0026ldquo;total_amount\u0026rdquo;), count(\u0026quot;*\u0026quot;).alias(\u0026ldquo;transaction_count\u0026rdquo;), avg(\u0026ldquo;amount\u0026rdquo;).alias(\u0026ldquo;avg_amount\u0026rdquo;) ) .cache()\nMultiple outputs để maximize resource usage df_processed.write.mode(\u0026ldquo;overwrite\u0026rdquo;) .partitionBy(\u0026ldquo;date\u0026rdquo;) .parquet(\u0026ldquo;s3://your-bucket/output/summary/\u0026rdquo;)\ndf_processed.filter(col(\u0026ldquo;total_amount\u0026rdquo;) \u0026gt; 1000) .write.mode(\u0026ldquo;overwrite\u0026rdquo;) .json(\u0026ldquo;s3://your-bucket/output/high-value/\u0026rdquo;)\nspark.stop() ``\nSuccess Criteria Validation Cost Check: aws ce get-cost-and-usage \\\r--time-period Start=2024-01-01,End=2024-01-02 \\\r--granularity DAILY \\\r--metrics BlendedCost \\\r--group-by Type=DIMENSION,Key=SERVICE\nPerformance Check:\nMonitor job completion time Check cluster utilization metrics Verify data processing accuracy Reliability Check:\nSimulate spot interruption Verify job recovery Check data consistency Kết luận Phần 2 Những gì đã học được: ✅ EMR Managed Scaling: Thiết lập và cấu hình ✅ Cost Optimization: Giảm 40% chi phí với dynamic scaling ✅ Performance Tuning: Tối ưu hóa Spark cho auto-scaling ✅ Monitoring: Theo dõi scaling events và metrics ✅ Troubleshooting: Xử lý common issues ✅ Production Patterns: Best practices cho real-world usage Tổng kết tiết kiệm chi phí: Phần 1 (Spot): 39% savings Phần 2 (Auto Scaling): 40% additional savings Combined: ~65% total cost reduction Next Steps: Trong Phần 3, chúng ta sẽ thiết lập comprehensive monitoring và alerting system để đảm bảo cluster hoạt động optimal và cost-effective.\nPro Tip: Trong production, combine auto-scaling với scheduled scaling cho predictable workloads để achieve tối đa 70-80% cost savings!\nTiếp theo: Phần 3: Monitoring \u0026amp; Alerting để complete cost optimization journey.\n"
},
{
	"uri": "http://localhost:1313/000058-SessionManager/vi/3-mornitoring/",
	"title": "Phần 3: Giám sát &amp; Cảnh báo",
	"tags": [],
	"description": "",
	"content": "Phần 3: Giám sát \u0026amp; Cảnh báo EMR - Khả năng quan sát hoàn chỉnh Trong phần cuối này, bạn sẽ thiết lập hệ thống giám sát và cảnh báo toàn diện cho các cluster EMR đã được tối ưu hóa chi phí để đảm bảo chúng hoạt động hiệu quả và trong ngân sách ở môi trường production.\nNhững gì bạn sẽ học Giám sát thời gian thực các cluster EMR và chi phí Cảnh báo chủ động cho các vấn đề về hiệu suất và chi phí Dashboard tùy chỉnh cho các bên liên quan khác nhau Khắc phục tự động các vấn đề thường gặp Theo dõi chi phí và tối ưu hóa các khuyến nghị [Nội dung tiếng Việt tương tự như bản tiếng Anh\u0026hellip;]\nKết luận Những gì bạn đã hoàn thành: ✅ Giám sát hoàn chỉnh: Giám sát cluster và chi phí thời gian thực ✅ Cảnh báo chủ động: Cảnh báo đa cấp cho các tình huống khác nhau ✅ Khắc phục tự động: Khả năng tự phục hồi cho các vấn đề thường gặp ✅ Theo dõi chi phí: Phân tích chi phí chi tiết và quản lý ngân sách ✅ Sẵn sàng production: Triển khai Lambda và lập lịch Tóm tắt tiết kiệm chi phí cuối cùng: Phần 1 (Spot Instances): Tiết kiệm 39% Phần 2 (Auto Scaling): Tiết kiệm thêm 40% Phần 3 (Monitoring): Tiết kiệm thêm 15% thông qua tối ưu hóa Tổng tiết kiệm kết hợp: Giảm chi phí ~70% Tác động thực tế: Công ty nhỏ: $2,000/tháng → $600/tháng = Tiết kiệm $1,400 Công ty trung bình: $10,000/tháng → $3,000/tháng = Tiết kiệm $7,000 Doanh nghiệp lớn: $40,000/tháng → $12,000/tháng = Tiết kiệm $28,000 Các chỉ số thành công chính: Giảm chi phí: Đạt được mức tiết kiệm trung bình 70% Độ tin cậy: 99.9% uptime với khắc phục tự động Hiệu suất: Duy trì hoặc cải thiện thời gian hoàn thành job Hiệu quả vận hành: Giảm 80% can thiệp thủ công Mẹo chuyên nghiệp: Hệ thống giám sát tự hoàn vốn chỉ bằng việc ngăn chặn một lần vượt chi phí lớn hoặc sự cố hiệu suất!\nChúc mừng! Bạn đã hoàn thành Workshop tối ưu hóa chi phí EMR toàn diện. Các cluster của bạn hiện đang chạy với hiệu quả tối đa, chi phí tối thiểu và khả năng quan sát đầy đủ.\nCác bước tiếp theo: Áp dụng các mẫu này cho workload production của bạn và tận hưởng việc tiết kiệm chi phí đáng kể!\n"
},
{
	"uri": "http://localhost:1313/000058-SessionManager/vi/4-workload-scheduling/",
	"title": "Phần 4: Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Phần 4: Dọn dẹp tài nguyên - Quản lý chi phí Sau khi hoàn thành workshop, việc dọn dẹp tất cả tài nguyên là rất quan trọng để tránh các khoản phí không mong muốn. Phần này cung cấp quy trình dọn dẹp toàn diện cho tất cả tài nguyên được tạo trong workshop.\nMục tiêu dọn dẹp Terminate EMR clusters và các tài nguyên liên quan Xóa CloudWatch alarms, dashboards, và custom metrics Xóa SNS topics và subscriptions Dọn dẹp Lambda functions và EventBridge rules Xóa S3 buckets và logs (nếu có tạo) Xác minh dọn dẹp hoàn tất để tránh phí Cảnh báo quan trọng QUAN TRỌNG: Việc xóa tài nguyên không thể hoàn tác. Đảm bảo bạn đã sao lưu dữ liệu quan trọng trước khi tiến hành.\nTác động chi phí: Để tài nguyên chạy có thể tốn $50-200+ mỗi ngày cho một EMR cluster.\n[Nội dung tiếng Việt tương tự như bản tiếng Anh\u0026hellip;]\nKết luận Chúc mừng! Bạn đã hoàn thành việc dọn dẹp tài nguyên một cách an toàn.\nChecklist cuối cùng: Tất cả EMR clusters đã terminate CloudWatch alarms và dashboards đã xóa SNS topics đã xóa Lambda functions đã xóa S3 buckets đã dọn dẹp Kiểm tra AWS Console "
},
{
	"uri": "http://localhost:1313/000058-SessionManager/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/000058-SessionManager/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]